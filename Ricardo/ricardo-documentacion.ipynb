{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "170103b0",
   "metadata": {},
   "source": [
    "### IMPORTACIONES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ebca0f4-6ccb-4b81-bfd4-b4c137b0f819",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re #regex para validar si existe subfijos\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "from scipy.signal import savgol_filter\n",
    "from sklearn.decomposition import PCA\n",
    "from numpy import trapz\n",
    "from scipy.ndimage import gaussian_filter1d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a320962-6177-4040-8293-a6d0225bd906",
   "metadata": {},
   "source": [
    "### LECTURA DE ARCHIVOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "696c7108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Ramanshift  collagen  collagen.1  collagen.2  collagen.3  collagen.4  \\\n",
      "0     1801.26     0.117       0.123       0.098       0.097       0.115   \n",
      "1     1797.41     0.118       0.124       0.099       0.098       0.116   \n",
      "2     1793.55     0.119       0.124       0.100       0.098       0.117   \n",
      "3     1789.69     0.118       0.122       0.099       0.097       0.117   \n",
      "4     1785.84     0.118       0.121       0.099       0.096       0.116   \n",
      "\n",
      "   collagen.5  collagen.6  collagen.7  collagen.8  ...  DNA.100  DNA.101  \\\n",
      "0       0.129       0.130       0.144       0.129  ...    0.154    0.150   \n",
      "1       0.130       0.131       0.145       0.129  ...    0.154    0.152   \n",
      "2       0.131       0.132       0.145       0.130  ...    0.155    0.153   \n",
      "3       0.131       0.132       0.146       0.131  ...    0.155    0.154   \n",
      "4       0.130       0.131       0.146       0.131  ...    0.155    0.155   \n",
      "\n",
      "   DNA.102  DNA.103  DNA.104  DNA.105  DNA.106  DNA.107  DNA.108  DNA.109  \n",
      "0    0.154    0.164    0.157    0.158    0.152    0.147    0.139    0.148  \n",
      "1    0.155    0.164    0.158    0.160    0.153    0.147    0.140    0.149  \n",
      "2    0.156    0.165    0.160    0.161    0.154    0.148    0.141    0.150  \n",
      "3    0.157    0.165    0.160    0.163    0.155    0.149    0.142    0.151  \n",
      "4    0.157    0.166    0.160    0.163    0.155    0.149    0.143    0.151  \n",
      "\n",
      "[5 rows x 732 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Lee el archivo CSV\n",
    "df = pd.read_csv('limpio.csv', delimiter=',')\n",
    "\n",
    "# Muestra las primeras filas del DataFrame para verificar\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d2e095",
   "metadata": {},
   "source": [
    " ### Verificamos si se tiene los subfijos al leer el archivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6da0c3c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se eliminaron los sufijos numéricos de los encabezados.\n",
      "   Ramanshift  collagen  collagen  collagen  collagen  collagen  collagen  \\\n",
      "0     1801.26     0.117     0.123     0.098     0.097     0.115     0.129   \n",
      "1     1797.41     0.118     0.124     0.099     0.098     0.116     0.130   \n",
      "2     1793.55     0.119     0.124     0.100     0.098     0.117     0.131   \n",
      "3     1789.69     0.118     0.122     0.099     0.097     0.117     0.131   \n",
      "4     1785.84     0.118     0.121     0.099     0.096     0.116     0.130   \n",
      "\n",
      "   collagen  collagen  collagen  ...    DNA    DNA    DNA    DNA    DNA  \\\n",
      "0     0.130     0.144     0.129  ...  0.154  0.150  0.154  0.164  0.157   \n",
      "1     0.131     0.145     0.129  ...  0.154  0.152  0.155  0.164  0.158   \n",
      "2     0.132     0.145     0.130  ...  0.155  0.153  0.156  0.165  0.160   \n",
      "3     0.132     0.146     0.131  ...  0.155  0.154  0.157  0.165  0.160   \n",
      "4     0.131     0.146     0.131  ...  0.155  0.155  0.157  0.166  0.160   \n",
      "\n",
      "     DNA    DNA    DNA    DNA    DNA  \n",
      "0  0.158  0.152  0.147  0.139  0.148  \n",
      "1  0.160  0.153  0.147  0.140  0.149  \n",
      "2  0.161  0.154  0.148  0.141  0.150  \n",
      "3  0.163  0.155  0.149  0.142  0.151  \n",
      "4  0.163  0.155  0.149  0.143  0.151  \n",
      "\n",
      "[5 rows x 732 columns]\n"
     ]
    }
   ],
   "source": [
    "if any(re.search(r'\\.\\d+$', col) for col in df.columns):\n",
    "    # Si hay columnas con sufijos, eliminarlos\n",
    "    df.columns = [re.sub(r'\\.\\d+$', '', col) for col in df.columns]\n",
    "    print(\"Se eliminaron los sufijos numéricos de los encabezados.\")\n",
    "# Muestra las primeras filas del DataFrame para verificar\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "918efba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Encabezados únicos:\n",
      "Index(['Ramanshift', 'collagen', 'glycogen', 'lipids', 'DNA'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "unique_headers = df.columns.unique()\n",
    "print(\"\\nEncabezados únicos:\")\n",
    "print(unique_headers)\n",
    "\n",
    "# Identificar los tipos únicos de valores en los encabezados\n",
    "unique_types = set(col for col in df.columns if col != \"Ramanshift\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae506a94-5230-4242-86ff-bcb332d1cf1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colores para cada tipo\n",
    "colors = plt.cm.tab20.colors  # Una paleta de colores suficientemente grande\n",
    "color_map = {unique: colors[i % len(colors)] for i, unique in enumerate(unique_types)}\n",
    "\n",
    "# Graficar cada tipo una sola vez en la leyenda\n",
    "plt.figure(figsize=(14, 10))\n",
    "\n",
    "for unique_type in unique_types:\n",
    "    # Filtrar las columnas correspondientes al tipo actual\n",
    "    columns = [col for col in df.columns if col.startswith(unique_type)]\n",
    "    \n",
    "    # Graficar todas las columnas del tipo actual\n",
    "    for col in columns:\n",
    "        plt.plot(df['Ramanshift'], df[col], color=color_map[unique_type], alpha=0.6)\n",
    "    \n",
    "    # Agregar una entrada en la leyenda solo para el tipo (una vez)\n",
    "    plt.plot([], [], label=unique_type, color=color_map[unique_type])  # Dummy plot for legend\n",
    "\n",
    "# Etiquetas y leyendas\n",
    "plt.title(\"Espectros Raman\", fontsize=16)\n",
    "plt.xlabel(\"Raman Shift (cm⁻¹)\", fontsize=14)\n",
    "plt.ylabel(\"Intensidad\", fontsize=14)\n",
    "plt.legend(title=\"Tipos\", fontsize=12, loc='upper right', frameon=False)\n",
    "plt.grid(True)\n",
    "\n",
    "# Mostrar la gráfica\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "154327d0",
   "metadata": {},
   "source": [
    "### En este caso pediremos al usuario ingresar algun tipo para graficar, para tener una idea de como se ve los espectros para cada uno de los tipos existentes en el archivo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "401b8b95",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>PD:</b> Aqui solo se mostraran hasta 10 como cantidad maxima de columnas para tipo, es para una referencia y no tener una carga de datos excesiva \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd222d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurar el tipo de espectro que se desea graficar\n",
    "#tipo_espectro = input(f\"Ingrese el tipo de espectro para graficar (opciones: {', '.join(unique_types)}): \").strip()\n",
    "tipo_espectro = \"collagen\"\n",
    "# Filtrar las columnas correspondientes al tipo de espectro ingresado\n",
    "columnas_tipo = [col for col in df.columns if col.startswith(tipo_espectro)]\n",
    "\n",
    "if columnas_tipo:\n",
    "    # Limitar el número de columnas graficadas\n",
    "    max_columns = 10\n",
    "    columnas_tipo = columnas_tipo[:max_columns]\n",
    "\n",
    "    # Reducir la cantidad de datos graficados\n",
    "    sampled_df = df.iloc[::10, :]\n",
    "\n",
    "    # Crear la gráfica\n",
    "    plt.figure(figsize=(14, 8))\n",
    "\n",
    "    # Graficar todas las líneas sin leyenda\n",
    "    for col in columnas_tipo:\n",
    "        plt.plot(sampled_df['Ramanshift'], sampled_df[col], alpha=0.7)\n",
    "\n",
    "    # Añadir una entrada única en la leyenda para el tipo\n",
    "    plt.plot([], [], label=tipo_espectro, color='black') \n",
    "\n",
    "    # Etiquetas y leyenda\n",
    "    plt.title(f\"Espectro Raman - {tipo_espectro} (muestra de columnas y filas)\", fontsize=16)\n",
    "    plt.xlabel(\"Raman Shift (cm⁻¹)\", fontsize=14)\n",
    "    plt.ylabel(\"Intensidad\", fontsize=14)\n",
    "    plt.legend(title=\"Espectros\", fontsize=10, loc='upper right', frameon=False)\n",
    "    plt.grid(True)\n",
    "\n",
    "    # Mostrar la gráfica\n",
    "    plt.show()\n",
    "else:\n",
    "    print(f\"No se encontraron columnas para el tipo de espectro '{tipo_espectro}'. Verifique el nombre e intente nuevamente.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2ed2c0",
   "metadata": {},
   "source": [
    "# <center>Analisis PCA</center>\n",
    "### ¿Por qué utilizar PCA en espectros?\n",
    "En datos espectroscópicos (como los Raman), los conjuntos de datos suelen tener alta dimensionalidad y las variables (picos) pueden estar correlacionadas. El PCA es útil porque:\n",
    "\n",
    "**Reduce la dimensionalidad:** Permite analizar un número menor de variables representativas. <br>\n",
    "**Captura patrones esenciales:** Identifica las características espectrales clave. <br>\n",
    "**Mejora la visualización:** Ayuda a visualizar datos complejos en gráficos 2D o 3D.  <br>\n",
    "**Preprocesamiento:** Facilita la clasificación o el análisis posterior (por ejemplo, identificación de muestras)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00109167",
   "metadata": {},
   "source": [
    "<img src=pca-analysis.gif>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1573d467",
   "metadata": {},
   "source": [
    "### Cálculo del PCA\n",
    "**Calcular la matriz de covarianza:** Representa cómo varían las variables juntas.<br>\n",
    "**Obtener los valores y vectores propios:** Los valores propios determinan la importancia (varianza explicada) de cada componente, y los vectores propios indican la dirección de los nuevos ejes. <br>\n",
    "**Proyección de los datos:** Transformar los datos originales en los nuevos ejes definidos por los componentes principales."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feea4ac0",
   "metadata": {},
   "source": [
    "### Aplicación práctica en espectros\n",
    "#### En espectros Raman:\n",
    "\n",
    "**Objetivo:** Identificar patrones comunes entre muestras (como grupos químicos) o distinguir diferencias entre ellas. <br>\n",
    "**Componentes principales:** Representan características espectrales clave que explican la mayoría de las variaciones entre los espectros. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "360ef353",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Limitaciones PCA:</b> Es una técnica lineal, lo que significa que no captura relaciones no lineales en los datos.\n",
    "Los componentes principales pueden ser difíciles de interpretar físicamente.\n",
    "Depende de la correcta estandarización y limpieza de los datos.\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81cfbac",
   "metadata": {},
   "source": [
    "# <center>Fundamento matemático</center>\n",
    "\n",
    "### 1. Matriz de datos\n",
    "Dado un conjunto de datos con \n",
    "𝑚\n",
    "m muestras y \n",
    "𝑛\n",
    "n variables, representamos los datos en una matriz de datos \n",
    "𝑋\n",
    "X de tamaño \n",
    "𝑚\n",
    "×\n",
    "𝑛\n",
    "m×n:\n",
    "$$\n",
    "X = \n",
    "\\begin{bmatrix}\n",
    "x_{11} & x_{12} & \\dots & x_{1n} \\\\\n",
    "x_{21} & x_{22} & \\dots & x_{2n} \\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "x_{m1} & x_{m2} & \\dots & x_{mn}\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Donde cada fila es una muestra, y cada columna es una variable (por ejemplo, la intensidad de un espectro en una longitud de onda específica).\n",
    "\n",
    "### 2. Estandarización\n",
    "El PCA requiere que las variables tengan media 0 y desviación estándar 1. Para ello, estandarizamos cada variable:\n",
    "\n",
    "$$\n",
    "z_{ij} = \\frac{x_{ij} - \\mu_j}{\\sigma_j}\n",
    "$$\n",
    "\n",
    "#### 1. Fórmula para estandarización de los datos\n",
    "\n",
    "$$\n",
    "z_{ij} = \\frac{x_{ij} - \\mu_j}{\\sigma_j}\n",
    "$$\n",
    "\n",
    "Donde:\n",
    "\n",
    "- \\( \\mu_j \\): Media de la variable \\( j \\).\n",
    "- \\( \\sigma_j \\): Desviación estándar de la variable \\( j \\).\n",
    "\n",
    "Esto nos da una nueva matriz \\( Z \\), estandarizada.\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a30f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Volver a realizar la estandarización con las columnas corregidas\n",
    "data_no_suffix = df.drop(columns=[\"Ramanshift\"])  # Eliminar la columna 'Ramanshift'\n",
    "\n",
    "# Estandarizar los datos nuevamente\n",
    "scaler = StandardScaler()\n",
    "data_standardized_no_suffix = scaler.fit_transform(data_no_suffix)\n",
    "\n",
    "\n",
    "# Convertir la matriz estandarizada en un DataFrame para inspección\n",
    "data_standardized_no_suffix_df = pd.DataFrame(data_standardized_no_suffix, columns=data_no_suffix.columns)\n",
    "\n",
    "# Mostrar las primeras filas del DataFrame estandarizado sin sufijos\n",
    "data_standardized_no_suffix_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084ff7a6",
   "metadata": {},
   "source": [
    "### 3. Matriz de covarianza\n",
    "\n",
    "La matriz de covarianza mide cómo varían las variables entre sí:\n",
    "\n",
    "$$\n",
    "C = \\frac{1}{m - 1} Z^\\top Z\n",
    "$$\n",
    "\n",
    "Donde:\n",
    "\n",
    "- \\( C \\): Es la matriz de covarianza (\\( n \\times n \\)).\n",
    "- \\( Z^\\top \\): La transpuesta de la matriz estandarizada \\( Z \\).\n",
    "\n",
    "Cada elemento de \\( C \\), \\( c_{ij} \\), mide la covarianza entre las variables \\( i \\) y \\( j \\):\n",
    "\n",
    "$$\n",
    "c_{ij} = \\frac{1}{m-1} \\sum_{k=1}^m (z_{ki} - \\bar{z}_i)(z_{kj} - \\bar{z}_j)\n",
    "$$\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c86d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular la matriz de covarianza a partir de los datos estandarizados\n",
    "covariance_matrix = np.cov(data_standardized_no_suffix.T)\n",
    "\n",
    "# Convertir la matriz de covarianza a un DataFrame para visualización\n",
    "covariance_matrix_df = pd.DataFrame(\n",
    "    covariance_matrix,\n",
    "    index=data_no_suffix.columns,\n",
    "    columns=data_no_suffix.columns\n",
    ")\n",
    "\n",
    "# Mostrar las primeras filas de la matriz de covarianza\n",
    "covariance_matrix_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c32b8d69",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Matriz De Covarianza Raman</b> Se ha calculado la matriz de covarianza a partir de los datos estandarizados. Esta matriz representa cómo varían las variables (columnas del espectro) entre sí.\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dcb2cc2",
   "metadata": {},
   "source": [
    "### 4. Descomposición en valores propios\n",
    "\n",
    "El PCA se basa en encontrar los vectores propios (\\( v \\)) y los valores propios (\\( \\lambda \\)) de la matriz de covarianza:\n",
    "\n",
    "$$\n",
    "C v = \\lambda v\n",
    "$$\n",
    "\n",
    "Donde:\n",
    "\n",
    "- \\( v \\): Es el vector propio (dirección del nuevo eje).\n",
    "- \\( \\lambda \\): Es el valor propio (cuánta varianza explica ese eje).\n",
    "\n",
    "Los valores propios están ordenados de mayor a menor y representan la cantidad de varianza explicada por cada componente principal.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92da524e-c628-432e-87c5-9c763a9c68d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descomposición en valores propios y vectores propios\n",
    "eigenvalues, eigenvectors = np.linalg.eig(covariance_matrix)\n",
    "\n",
    "# Convertir los valores propios en un DataFrame para inspección\n",
    "eigenvalues_df = pd.DataFrame(eigenvalues, columns=[\"Valor Propio\"])\n",
    "\n",
    "# Convertir los vectores propios en un DataFrame para inspección\n",
    "eigenvectors_df = pd.DataFrame(\n",
    "    eigenvectors,\n",
    "    index=data_no_suffix.columns,\n",
    "    columns=[f\"PC{i+1}\" for i in range(eigenvectors.shape[1])]\n",
    ")\n",
    "\n",
    "# Mostrar los valores propios y vectores propios\n",
    "eigenvalues_df.head()\n",
    "eigenvectors_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8ed705-1eeb-4d38-a308-e506b0b689a3",
   "metadata": {},
   "source": [
    "*La descomposición en valores propios y vectores propios de la matriz de covarianza se ha realizado correctamente:*<br>\n",
    "**Valores propios (eigenvalues):** Indican la cantidad de varianza explicada por cada componente principal.<br>\n",
    "**Vectores propios (eigenvectors):** Representan las direcciones (ejes) de los nuevos componentes principales en el espacio original."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5315f3c6-7d58-45b1-8984-39f24fb0781d",
   "metadata": {},
   "source": [
    "### 5 Transformación de los datos\n",
    "\n",
    "Los datos originales se transforman proyectándolos en los ejes definidos por los vectores propios:\n",
    "\n",
    "$$\n",
    "T = Z V\n",
    "$$\n",
    "\n",
    "Donde:\n",
    "\n",
    "- \\( T \\): Matriz transformada (nuevos datos en el espacio de los componentes principales).\n",
    "- \\( V \\): Matriz cuyas columnas son los vectores propios (direcciones principales).\n",
    "\n",
    "Cada fila de \\( T \\) es la representación de una muestra en el espacio reducido.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c1b839-699d-4a83-a82b-3c9dbd78c768",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proyección de los datos originales en los ejes definidos por los componentes principales\n",
    "transformed_data = np.dot(data_standardized_no_suffix, eigenvectors)\n",
    "\n",
    "# Convertir los datos transformados en un DataFrame para inspección\n",
    "transformed_data_df = pd.DataFrame(\n",
    "    transformed_data,\n",
    "    columns=[f\"PC{i+1}\" for i in range(transformed_data.shape[1])]\n",
    ")\n",
    "\n",
    "# Mostrar los primeros datos transformados\n",
    "transformed_data_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b51e995-7fcb-4e37-8a1e-73cd4061d5b8",
   "metadata": {},
   "source": [
    "*Resultados:* <br>\n",
    "**Cada fila:** Representa una muestra en el espacio PCA. <br>\n",
    "**Cada columna (PC1, PC2, ...):** Representa un componente principal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdedce14-c4aa-4c79-add1-5e865c4dbe3e",
   "metadata": {},
   "source": [
    "### 6. Varianza explicada\n",
    "\n",
    "La proporción de varianza explicada por cada componente principal es:\n",
    "\n",
    "$$\n",
    "\\text{Varianza explicada} = \\frac{\\lambda_i}{\\sum \\lambda}\n",
    "$$\n",
    "\n",
    "Esto nos dice cuánto contribuye cada componente principal a la variabilidad total de los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8193ece6-8c55-407d-a307-2966a6974fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular la varianza explicada por cada componente principal\n",
    "explained_variance = eigenvalues / np.sum(eigenvalues)\n",
    "\n",
    "# Calcular la varianza acumulada\n",
    "cumulative_variance = np.cumsum(explained_variance)\n",
    "\n",
    "pc1 = transformed_data[:, 0]\n",
    "pc2 = transformed_data[:, 1]\n",
    "\n",
    "# Crear un gráfico de dispersión utilizando PC1 y PC2\n",
    "#plt.figure(figsize=(10, 6))\n",
    "#plt.scatter(pc1, pc2, alpha=0.7, edgecolor='k')\n",
    "#plt.xlabel(\"Componente Principal 1 (PC1)\", fontsize=14)\n",
    "#plt.ylabel(\"Componente Principal 2 (PC2)\", fontsize=14)\n",
    "#plt.title(\"Proyección de Espectros en el Espacio PCA\", fontsize=16)\n",
    "#plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8df87d4-264a-44eb-8de8-e7cb5753a7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Leer el archivo CSV y excluir la primera columna (ejemplo: Ramanshift)\n",
    "data = df.iloc[:, 1:]\n",
    "\n",
    "# Obtener las categorías desde los nombres de las columnas\n",
    "# Se asume que los nombres de las columnas contienen las categorías como parte del texto\n",
    "categories = [col.split('_')[0] for col in data.columns]  # Divide por un delimitador como \"_\" (ajusta según tu formato)\n",
    "unique_categories = list(set(categories))  # Categorías únicas\n",
    "\n",
    "# Asignar un color único a cada categoría\n",
    "colors = plt.cm.tab10.colors  # Paleta de colores\n",
    "category_colors = {category: colors[i % len(colors)] for i, category in enumerate(unique_categories)}\n",
    "\n",
    "# Escalar los datos\n",
    "scaler = StandardScaler()\n",
    "data_scaled = scaler.fit_transform(data.T)  # Transposición para que las características sean columnas\n",
    "\n",
    "# Aplicar PCA\n",
    "pca = PCA(n_components=2)\n",
    "pca_result = pca.fit_transform(data_scaled)\n",
    "\n",
    "# Graficar el PCA con colores por tipo\n",
    "plt.figure(figsize=(10, 6))\n",
    "for category in unique_categories:\n",
    "    indices = [i for i, cat in enumerate(categories) if cat == category]\n",
    "    plt.scatter(\n",
    "        pca_result[indices, 0],\n",
    "        pca_result[indices, 1],\n",
    "        label=category,\n",
    "        color=category_colors[category],\n",
    "        alpha=0.7,\n",
    "        edgecolor='k'\n",
    "    )\n",
    "\n",
    "# Etiquetas y leyenda\n",
    "plt.xlabel('PC1', fontsize=14)\n",
    "plt.ylabel('PC2', fontsize=14)\n",
    "plt.title('Proyección PCA', fontsize=16)\n",
    "plt.legend(loc='best', fontsize=10)\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be35e3a",
   "metadata": {},
   "source": [
    "## <center>¿Por qué suavizar los datos antes del PCA?</center>\n",
    "\n",
    "### Reducción de ruido: \n",
    "\n",
    "En espectros, el ruido puede distorsionar las señales reales y hacer que el PCA se enfoque en variaciones no representativas.\n",
    "Suavizar elimina fluctuaciones pequeñas e irrelevantes, dejando solo las tendencias principales.<br>\n",
    "\n",
    "### Mejor representación de los patrones:\n",
    "\n",
    "Las características significativas (picos y valles) de un espectro se destacan mejor después del suavizado.\n",
    "El PCA trabajará sobre señales más limpias y representativas, en lugar de desviaciones causadas por el ruido.\n",
    "\n",
    "### Reducir complejidad: \n",
    "\n",
    "Suavizar puede disminuir la cantidad de detalles excesivos en los datos, facilitando la identificación de las principales componentes. \n",
    "\n",
    "\n",
    "### Mejor interpretación de los resultados:\n",
    "\n",
    "Los componentes principales extraídos del PCA serán más fáciles de relacionar con características relevantes de los datos (como picos en un espectro).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b198fd5e",
   "metadata": {},
   "source": [
    "## <center> ¿Cuándo no es necesario suavizar? </center> \n",
    "Si los datos ya son de alta calidad y el ruido es mínimo, el suavizado puede no ser necesario.\n",
    "Un exceso de suavizado puede eliminar detalles importantes, lo que podría llevar a perder información relevante."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec18de1",
   "metadata": {},
   "source": [
    "# <center>Métodos de suavizado comunes</center>\n",
    "\n",
    "## **1. Savitzky-Golay Filter**\n",
    "- Realiza un ajuste polinómico local en una ventana móvil.\n",
    "- Ideal para espectros, ya que preserva los picos y las características de la señal.\n",
    "\n",
    "**Fórmula:**\n",
    "$$\n",
    "y'(t) = \\sum_{k=-m}^{m} c_k \\cdot x(t+k)\n",
    "$$\n",
    "\n",
    "Donde:\n",
    "\n",
    "- $$y'(t)$$: Señal suavizada.\n",
    "- $$c_k$$: Coeficientes del polinomio.\n",
    "- $$x(t+k)$$: Valores originales en la ventana móvil.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a691cae",
   "metadata": {},
   "source": [
    "<img src=filtro-sg.ppm>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b9bf4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parámetros para suavizar\n",
    "window_length = 11  # Longitud de la ventana (debe ser impar)\n",
    "polyorder = 3       # Orden del polinomio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b15a71",
   "metadata": {},
   "source": [
    "### 1. <font color=\"blue\">window_length:</font> Longitud de la ventana\n",
    "**Definición:** Es el número de puntos consecutivos que se utilizan para ajustar un polinomio en el proceso de suavizado.\n",
    "#### Requisitos:\n",
    "Debe ser un número entero impar (por ejemplo, 5, 7, 9, 11, etc.).\n",
    "Debe ser mayor que el orden del polinomio (polyorder).\n",
    "### Impacto:\n",
    "**Ventana pequeña:** El suavizado será más localizado y detallado, pero puede no eliminar bien el ruido.<br>\n",
    "**Ventana grande:** El suavizado será más amplio y eliminará más ruido, pero podría borrar picos o detalles importantes.\n",
    "\n",
    "### 2. <font color=\"blue\">polyorder:</font> Orden del polinomio\n",
    "**Definición:** Es el grado del polinomio que se ajusta a los puntos dentro de cada ventana.\n",
    "### Requisitos:\n",
    "Debe ser un número entero no negativo.\n",
    "Debe ser menor que el tamaño de la ventana (window_length).\n",
    "### Impacto:\n",
    "**Orden bajo (e.g., 2 o 3):** Se ajusta a tendencias generales y no captura oscilaciones rápidas.<br>\n",
    "**Orden alto (e.g., 4 o más):** Captura más detalles locales, pero puede amplificar el ruido si se usa con datos ruidosos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c4f9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar Savitzky-Golay al dataset\n",
    "data_smoothed = savgol_filter(df.iloc[:, 1:], window_length=window_length, polyorder=polyorder, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c68874",
   "metadata": {},
   "source": [
    "### Cómo funciona <font color=\"blue\">savgol_filter</font>\n",
    "El filtro realiza un ajuste polinómico en ventanas móviles de datos. Dentro de cada ventana, se ajusta un polinomio de un grado específico a los datos y luego se usa ese polinomio para calcular el valor suavizado del punto central.\n",
    "\n",
    "**Ventana móvil:**<br>\n",
    "Es un subconjunto de datos de longitud definida por el parámetro window_length.<br>\n",
    "La ventana se mueve a través de la señal, centrada en cada punto que se va a suavizar.<br>\n",
    "**Ajuste polinómico:**<br>\n",
    "Dentro de cada ventana, se ajusta un polinomio de grado polyorder.<br>\n",
    "El valor del punto central de la ventana se reemplaza por el valor del polinomio ajustado.<br>\n",
    "**Repetición:**<br>\n",
    "El proceso se repite para cada punto de la señal, excepto en los extremos, donde la ventana no puede ser completamente centrada. En esos casos, se utiliza un método de extrapolación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb1829c-1943-4121-bd2f-c09d6c300b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un DataFrame con los datos suavizados\n",
    "df_smoothed = pd.DataFrame(data_smoothed, columns=df.columns[1:])\n",
    "df_smoothed.insert(0, 'Ramanshift', df['Ramanshift'])  # Insertar de vuelta la columna 'Ramanshift' que quitamos para\n",
    "#poder suavizar\n",
    "\n",
    "# Obtener los tipos únicos desde los nombres de las columnas\n",
    "unique_types = set(col.split('_')[0] for col in df.columns[1:])  # Ajusta el separador si es necesario\n",
    "\n",
    "# Crear un mapa de colores\n",
    "colors = plt.cm.tab20.colors  # con 20 colores si podra colorear\n",
    "color_map = {unique: colors[i % len(colors)] for i, unique in enumerate(unique_types)}\n",
    "\n",
    "# Graficar los espectros suavizados\n",
    "plt.figure(figsize=(14, 10))\n",
    "\n",
    "for unique_type in unique_types:\n",
    "    # Filtrar las columnas correspondientes al tipo actual\n",
    "    columns = [col for col in df.columns if col.startswith(unique_type)]\n",
    "    \n",
    "    # Graficar todas las columnas del tipo actual\n",
    "    for col in columns:\n",
    "        plt.plot(df_smoothed['Ramanshift'], df_smoothed[col], color=color_map[unique_type], alpha=0.6)\n",
    "    \n",
    "    # Agregar una entrada en la leyenda solo para el tipo (una vez)\n",
    "    plt.plot([], [], label=unique_type, color=color_map[unique_type])  # Dummy plot for legend\n",
    "\n",
    "# Etiquetas y leyendas\n",
    "plt.title(\"Espectros Raman Suavizados SG\", fontsize=16)\n",
    "plt.xlabel(\"Raman Shift (cm⁻¹)\", fontsize=14)\n",
    "plt.ylabel(\"Intensidad Suavizada\", fontsize=14)\n",
    "plt.legend(title=\"Tipos\", fontsize=12, loc='upper right', frameon=False)\n",
    "plt.grid(True)\n",
    "\n",
    "# Mostrar la gráfica\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b36fd074",
   "metadata": {},
   "source": [
    "## 2. Filtro Gaussiano\n",
    "El filtro gaussiano es una técnica de suavizado que se utiliza para reducir el ruido en los espectros (como los espectros Raman) preservando las características principales, como los picos. Este filtro aplica una convolución entre los datos espectrales y una función gaussiana, lo que atenúa las variaciones rápidas (ruido) y retiene los patrones de baja frecuencia (picos y formas importantes).\n",
    "\n",
    "### Cómo funciona el filtro gaussiano\n",
    "**Definición de la función gaussiana:** La función gaussiana es una curva en forma de campana que da más peso a los puntos cercanos al valor central. Matemáticamente, se define como:\n",
    "\n",
    "$$\n",
    "G(x) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} e^{-\\frac{x^2}{2\\sigma^2}}\n",
    "$$\n",
    "\n",
    "Donde: <br>\n",
    "G(x): Valor de la función gaussiana en un punto <br>\n",
    "σ: Desviación estándar, que determina el ancho de la curva gaussiana.\n",
    "\n",
    "**Aplicación en el espectro:**\n",
    "\n",
    "* Se toma una ventana alrededor de cada punto del espectro.\n",
    "* Se calcula un promedio ponderado de los valores dentro de la ventana, donde los pesos están determinados por la función gaussiana. <br>\n",
    "\n",
    "**Atenuación del ruido:**\n",
    "\n",
    "El ruido, que tiende a tener variaciones rápidas, se atenúa debido al promedio ponderado.\n",
    "Las características principales, como los picos del espectro, se preservan.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c617327",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Parámetros para el filtro gaussiano\n",
    "sigma = 2  # Desviación estándar del filtro\n",
    "\n",
    "# Aplicar el filtro gaussiano a los datos espectrales\n",
    "data_smoothed_gaussian = gaussian_filter1d(df.iloc[:, 1:].values, sigma=sigma, axis=0)\n",
    "\n",
    "# Crear un DataFrame con los datos suavizados\n",
    "df_smoothed_gaussian = pd.DataFrame(data_smoothed_gaussian, columns=df.columns[1:])\n",
    "df_smoothed_gaussian.insert(0, 'Ramanshift', df['Ramanshift'])  # Insertar la columna 'Ramanshift'\n",
    "\n",
    "# Obtener los tipos únicos desde los nombres de las columnas\n",
    "unique_types = set(col.split('_')[0] for col in df.columns[1:])  # Ajusta el separador si es necesario\n",
    "\n",
    "# Crear un mapa de colores\n",
    "colors = plt.cm.tab20.colors  # Paleta de colores suficientemente grande\n",
    "color_map = {unique: colors[i % len(colors)] for i, unique in enumerate(unique_types)}\n",
    "\n",
    "# Graficar los espectros suavizados\n",
    "plt.figure(figsize=(14, 10))\n",
    "\n",
    "for unique_type in unique_types:\n",
    "    # Filtrar las columnas correspondientes al tipo actual\n",
    "    columns = [col for col in df.columns if col.startswith(unique_type)]\n",
    "    \n",
    "    # Graficar todas las columnas del tipo actual\n",
    "    for col in columns:\n",
    "        plt.plot(df_smoothed_gaussian['Ramanshift'], df_smoothed_gaussian[col], color=color_map[unique_type], alpha=0.6)\n",
    "    \n",
    "    # Agregar una entrada en la leyenda solo para el tipo (una vez)\n",
    "    plt.plot([], [], label=unique_type, color=color_map[unique_type])  # Dummy plot for legend\n",
    "\n",
    "# Etiquetas y leyendas\n",
    "plt.title(\"Espectros Raman Suavizados con Filtro Gaussiano\", fontsize=16)\n",
    "plt.xlabel(\"Raman Shift (cm⁻¹)\", fontsize=14)\n",
    "plt.ylabel(\"Intensidad Suavizada\", fontsize=14)\n",
    "plt.legend(title=\"Tipos\", fontsize=12, loc='upper right', frameon=False)\n",
    "plt.grid(True)\n",
    "\n",
    "# Mostrar la gráfica\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4bd452",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficar los espectros suavizados para comparar con colores diferentes por tipo\n",
    "plt.figure(figsize=(20, 8))\n",
    "\n",
    "# Crear un mapa de colores\n",
    "unique_types = set(col.split('_')[0] for col in df_smoothed_gaussian.columns[1:])\n",
    "colors = plt.cm.tab20.colors\n",
    "color_map = {unique: colors[i % len(colors)] for i, unique in enumerate(unique_types)}\n",
    "\n",
    "# Subplot para el filtro gaussiano\n",
    "plt.subplot(1, 2, 1)\n",
    "for unique_type in unique_types:\n",
    "    columns = [col for col in df_smoothed_gaussian.columns if col.startswith(unique_type)]\n",
    "    for col in columns:\n",
    "        plt.plot(df_smoothed_gaussian['Ramanshift'], df_smoothed_gaussian[col], color=color_map[unique_type], alpha=0.6)\n",
    "    plt.plot([], [], label=unique_type, color=color_map[unique_type])  # Dummy plot for legend\n",
    "plt.title(\"Filtro Gaussiano\", fontsize=16)\n",
    "plt.xlabel(\"Raman Shift (cm⁻¹)\", fontsize=14)\n",
    "plt.ylabel(\"Intensidad Suavizada\", fontsize=14)\n",
    "plt.legend(title=\"Tipos\", fontsize=12, loc='upper right', frameon=False)\n",
    "plt.grid(True)\n",
    "\n",
    "# Subplot para el filtro Savitzky-Golay\n",
    "plt.subplot(1, 2, 2)\n",
    "for unique_type in unique_types:\n",
    "    columns = [col for col in df_smoothed.columns if col.startswith(unique_type)]\n",
    "    for col in columns:\n",
    "        plt.plot(df_smoothed['Ramanshift'], df_smoothed[col], color=color_map[unique_type], alpha=0.6)\n",
    "    plt.plot([], [], label=unique_type, color=color_map[unique_type])  # Dummy plot for legend\n",
    "plt.title(\"Filtro Savitzky-Golay\", fontsize=16)\n",
    "plt.xlabel(\"Raman Shift (cm⁻¹)\", fontsize=14)\n",
    "plt.ylabel(\"Intensidad Suavizada\", fontsize=14)\n",
    "plt.legend(title=\"Tipos\", fontsize=12, loc='upper right', frameon=False)\n",
    "plt.grid(True)\n",
    "\n",
    "# Ajustar y mostrar\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff46c6e",
   "metadata": {},
   "source": [
    "**Filtro de Savitzky-Golay:**\n",
    "* Utiliza un ajuste polinómico en una ventana móvil.\n",
    "* Si los parámetros de longitud de ventana (window_length) y orden del polinomio (polyorder) están ajustados de manera conservadora, el resultado será muy similar al de un filtro gaussiano. <br>\n",
    "\n",
    "**Filtro Gaussiano:**<br>\n",
    "* Realiza una convolución con una función gaussiana.\n",
    "* El parámetro clave es 𝜎 (desviación estándar), que controla la suavidad.<bR>\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "Si la longitud de ventana de Savitzky-Golay y 𝜎 en el filtro gaussiano son equivalentes en términos de suavizado, las gráficas resultantes serán casi idénticas.\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d30a8da1",
   "metadata": {},
   "source": [
    "#### Diferencias:\n",
    "Calcula la diferencia absoluta entre los datos suavizados por cada filtro:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8c94b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "difference = df_smoothed_gaussian.iloc[:, 1:] - df_smoothed.iloc[:, 1:]\n",
    "print(difference.abs().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e87ecc",
   "metadata": {},
   "source": [
    "# <center>Normalizacion de los espectros</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c22f6c",
   "metadata": {},
   "source": [
    "Normalizar el espectro es un proceso que consiste en escalar o transformar los datos de un espectro a un rango o referencia común. Esto se hace para poder comparar diferentes espectros entre sí, y para eliminar variaciones aleatorias en la amplitud de cada intensidad.\n",
    "### Métodos de Normalización y Sus Casos de Uso\n",
    "\n",
    "| **Método**                 | **Propósito**                                                                 |\n",
    "|----------------------------|------------------------------------------------------------------------------|\n",
    "| **Escalado Min-Max**       | Cuando los datos necesitan estar en un rango específico (por ejemplo, [0, 1]).|\n",
    "| **Z-Score (Estandarización)** | Cuando se necesita centrar y escalar los datos (por ejemplo, para PCA o agrupamiento). |\n",
    "| **Normalización por Área** | Comparar formas o perfiles (por ejemplo, en espectroscopía o cromatografía).  |\n",
    "| **Normalización por Máximo** | Resaltar intensidades relativas (por ejemplo, en datos espectrales).          |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fafe6480",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Normalización por valor máximo\n",
    "df_normalized_max = df.iloc[:, 1:].div(df.iloc[:, 1:].max(axis=0), axis=1)\n",
    "df_normalized_max.insert(0, 'Ramanshift', df['Ramanshift'])  # Reinsertar la columna 'Ramanshift'\n",
    "\n",
    "# 2. Normalización por área bajo la curva\n",
    "areas = trapz(df.iloc[:, 1:].values, x=df['Ramanshift'].values, axis=0)\n",
    "df_normalized_area = df.iloc[:, 1:].div(areas, axis=1)\n",
    "df_normalized_area.insert(0, 'Ramanshift', df['Ramanshift'])\n",
    "\n",
    "# 3. Normalización Z-Score\n",
    "scaler = StandardScaler()\n",
    "data_scaled = scaler.fit_transform(df.iloc[:, 1:])\n",
    "df_normalized_zscore = pd.DataFrame(data_scaled, columns=df.columns[1:])\n",
    "df_normalized_zscore.insert(0, 'Ramanshift', df['Ramanshift'])\n",
    "\n",
    "# Mostrar las primeras filas de los DataFrames normalizados para inspección\n",
    "\n",
    "df_normalized_max.head()\n",
    "df_normalized_area.head()\n",
    "df_normalized_zscore.head()\n",
    "#print(df_normalized_zscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005ce650",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_normalized_max.to_csv('normalized_max.csv', index=False)\n",
    "df_normalized_area.to_csv('normalized_area.csv', index=False)\n",
    "df_normalized_zscore.to_csv('normalized_zscore.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf67fd27-6462-45a9-9a21-3205367b8ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1. Eliminar sufijos numéricos de los nombres de las columnas\n",
    "df.columns = [re.sub(r'\\.\\d+$', '', col) for col in df.columns]\n",
    "\n",
    "# 2. Normalización por diferentes métodos\n",
    "\n",
    "# Normalización por valor máximo\n",
    "df_normalized_max = df.iloc[:, 1:].div(df.iloc[:, 1:].max(axis=0), axis=1)\n",
    "df_normalized_max.insert(0, 'Ramanshift', df['Ramanshift'])\n",
    "\n",
    "# Normalización por área bajo la curva\n",
    "areas = trapz(df.iloc[:, 1:].values, x=df['Ramanshift'].values, axis=0)\n",
    "df_normalized_area = df.iloc[:, 1:].div(areas, axis=1)\n",
    "df_normalized_area.insert(0, 'Ramanshift', df['Ramanshift'])\n",
    "\n",
    "# Normalización Z-Score\n",
    "scaler = StandardScaler()\n",
    "data_scaled = scaler.fit_transform(df.iloc[:, 1:])\n",
    "df_normalized_zscore = pd.DataFrame(data_scaled, columns=df.columns[1:])\n",
    "df_normalized_zscore.insert(0, 'Ramanshift', df['Ramanshift'])\n",
    "\n",
    "# Función para graficar espectros\n",
    "def plot_normalized_spectra(df_normalized, title):\n",
    "    # Obtener tipos únicos\n",
    "    unique_types = set(col.split('_')[0] for col in df_normalized.columns[1:])\n",
    "    \n",
    "    # Crear un mapa de colores\n",
    "    colors = plt.cm.tab20.colors\n",
    "    color_map = {unique: colors[i % len(colors)] for i, unique in enumerate(unique_types)}\n",
    "    \n",
    "    # Graficar\n",
    "    plt.figure(figsize=(14, 10))\n",
    "    for unique_type in unique_types:\n",
    "        columns = [col for col in df_normalized.columns if col.startswith(unique_type)]\n",
    "        for col in columns:\n",
    "            plt.plot(df_normalized['Ramanshift'], df_normalized[col], color=color_map[unique_type], alpha=0.6)\n",
    "        plt.plot([], [], label=unique_type, color=color_map[unique_type])  # Dummy plot for legend\n",
    "    \n",
    "    # Etiquetas y leyendas\n",
    "    plt.title(title, fontsize=16)\n",
    "    plt.xlabel(\"Raman Shift (cm⁻¹)\", fontsize=14)\n",
    "    plt.ylabel(\"Intensidad Normalizada\", fontsize=14)\n",
    "    plt.legend(title=\"Tipos\", fontsize=12, loc='upper right', frameon=False)\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d7ccda-8baa-4ed8-9416-b488829d2db0",
   "metadata": {},
   "source": [
    "## <center>Graficos normalizados, por tipo de normalizacion</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc311697-362f-478a-b435-70fb0b793c0b",
   "metadata": {},
   "source": [
    "### Normalización por Máximo\n",
    "\n",
    "La **normalización por máximo** ajusta los datos dividiendo cada valor por el valor máximo en su columna. Esto escala los valores al rango \\([0, 1]\\).\n",
    "\n",
    "**Fórmula:**\n",
    "\n",
    "$$\n",
    "x_{\\text{norm}} = \\frac{x}{x_{\\text{max}}}\n",
    "$$\n",
    "\n",
    "Donde:\n",
    "- \\( x \\): Valor original.\n",
    "- \\( x_{\\text{max}} \\): Valor máximo de la columna correspondiente.\n",
    "\n",
    "#### Propósito:\n",
    "- Resaltar las intensidades relativas en los datos.\n",
    "- Comparar espectros escalados a un rango uniforme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c373ede-22e1-4833-a526-7d5323297bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_normalized_spectra(df_normalized_max, \"Espectros Normalizados por Máximo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40571e65-3060-4cff-b1ba-8cdd1a7eacea",
   "metadata": {},
   "source": [
    "### Normalizados por Área\n",
    "La normalización por área es un método común para escalar datos espectrales, como los espectros Raman, que ajusta cada valor del espectro dividiendo por el área total bajo la curva. Esto asegura que el área total de cada espectro sea igual a 1, permitiendo comparaciones más equitativas de las formas relativas de los espectros.\n",
    "\n",
    "#### Cómo funciona la Normalización por Área\n",
    "\n",
    "#### Calcular el área bajo la curva (AUC):\n",
    "El área se calcula como la integral de la intensidad a lo largo de los valores del desplazamiento Raman (o eje X). \n",
    "\n",
    "En datos discretos, como los espectros Raman, se utiliza una suma aproximada o la **regla del trapecio** para estimar esta integral:\n",
    "\n",
    "$$\n",
    "A = \\int f(x) \\, dx \\approx \\sum_{i=1}^{n-1} \\frac{f(x_{i+1}) + f(x_i)}{2} (x_{i+1} - x_i)\n",
    "$$\n",
    "\n",
    "En Python, esto se logra con la función `numpy.trapz`.\n",
    "\n",
    "---\n",
    "\n",
    "#### Dividir cada valor por el área total:\n",
    "Una vez calculada el área (\\( A \\)), cada valor del espectro (\\( x \\)) se divide por \\( A \\):\n",
    "\n",
    "$$\n",
    "x_{\\text{norm}} = \\frac{x}{A}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "#### Resultado:\n",
    "- Los valores del espectro escalados estarán en una **escala relativa**.\n",
    "- El área bajo la curva del espectro normalizado será igual a **1**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3f0649-632f-429b-aab4-125af7052b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_normalized_spectra(df_normalized_area, \"Espectros Normalizados por Área\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a94ab50-ff95-468d-a6e8-73593ed2a539",
   "metadata": {},
   "source": [
    "## Normalizacion Z-Score (Estandarización)\n",
    "La normalización Z-Score, también conocida como estandarización, transforma los datos para que cada variable tenga una media de 0 y una desviación estándar de 1. Este método es especialmente útil para análisis estadísticos como el PCA, donde las escalas de las variables pueden afectar el resultado.\n",
    "\n",
    "### Fórmula del Z-Score\n",
    "\n",
    "Cada valor se transforma usando la fórmula:\n",
    "\n",
    "$$\n",
    "z = \\frac{x - \\mu}{\\sigma}\n",
    "$$\n",
    "\n",
    "Donde:\n",
    "- \\( x \\): Valor original.\n",
    "- \\( \\mu \\): Media de la variable.\n",
    "- \\( \\sigma \\): Desviación estándar de la variable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b247bc7-2e33-4c4e-b4b1-bb19a02f8a6c",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Interpretación de \n",
    "𝜎\n",
    "σ en espectros Raman</b> \n",
    "    <br><font color=red>Desviación estándar pequeña:</font> La intensidad de los valores está más concentrada alrededor de la media, indicando picos más homogéneos.<br>\n",
    "    <font color=red>Desviación estándar grande:</font> Los valores de intensidad están más dispersos, indicando variaciones significativas en el espectro.<br>\n",
    "</div>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1120912-7c57-42b6-9cdc-3c31b81036e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_normalized_spectra(df_normalized_zscore, \"Espectros Normalizados por Z-Score\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8b628a",
   "metadata": {},
   "source": [
    "# Corrección de Shirley\n",
    "## ¿Por qué se necesita la corrección de Shirley?\n",
    "\n",
    "### **Presencia de un fondo no lineal:**\n",
    "- Los espectros suelen incluir un fondo causado por:\n",
    "  - Efectos secundarios.\n",
    "  - Ruido.\n",
    "  - Respuesta del instrumento.\n",
    "- Este fondo no lineal puede superponerse con los picos de interés, complicando su análisis.\n",
    "\n",
    "### **Análisis preciso de los picos:**\n",
    "- Los picos en un espectro representan características físicas o químicas clave, como:\n",
    "  - Vibraciones moleculares.\n",
    "  - Estados electrónicos.\n",
    "- La corrección de Shirley elimina el fondo para que los picos sean más visibles y se puedan analizar con mayor precisión.\n",
    "\n",
    "### **Estandarización:**\n",
    "- Al eliminar el fondo, los espectros de diferentes muestras o instrumentos se pueden comparar directamente.\n",
    "\n",
    "---\n",
    "\n",
    "## ¿Cómo funciona la corrección de Shirley?\n",
    "- La corrección de Shirley modela el fondo como una curva no lineal y lo ajusta iterativamente:\n",
    "  1. El área **debajo de la curva ajustada** se iguala al área **sobre la curva** (en un rango definido del espectro).\n",
    "  2. Se asume que la contribución del fondo **aumenta con la intensidad acumulativa** del espectro.\n",
    "\n",
    "---\n",
    "\n",
    "## Aplicaciones de la corrección de Shirley\n",
    "\n",
    "### **XPS (Espectroscopía de Fotoelectrones de Rayos X):**\n",
    "- Elimina el fondo causado por emisiones secundarias de electrones.\n",
    "- Permite determinar con precisión la composición elemental y los estados químicos.\n",
    "\n",
    "### **Espectroscopía Raman:**\n",
    "- Corrige fondos de fluorescencia u otras señales amplias que ocultan los picos Raman.\n",
    "\n",
    "### **Espectroscopía UV-Vis e Infrarroja:**\n",
    "- Corrige líneas de base causadas por efectos de dispersión o absorción.\n",
    "\n",
    "---\n",
    "\n",
    "## Ventajas de la corrección de Shirley\n",
    "\n",
    "### **Preservación de los picos:**\n",
    "- Conserva la forma y el área de los picos, lo que la hace ideal para análisis cuantitativos y cualitativos.\n",
    "\n",
    "### **Versatilidad:**\n",
    "- Es efectiva para fondos no lineales, lo que la hace aplicable a una amplia variedad de técnicas espectroscópicas.\n",
    "\n",
    "### **Ajuste iterativo:**\n",
    "- Proporciona un método flexible que converge hacia una línea de base precisa.\n",
    "\n",
    "---\n",
    "\n",
    "## Limitaciones de la corrección de Shirley\n",
    "\n",
    "### **Requiere tiempo:**\n",
    "- Los procesos iterativos pueden ser computacionalmente costosos para conjuntos de datos grandes.\n",
    "\n",
    "### **Dependencia de los puntos iniciales/finales:**\n",
    "- Es necesario definir correctamente el rango del espectro donde se aplicará la corrección.\n",
    "\n",
    "### **Riesgo de sobrecorrección:**\n",
    "- Si no se aplica adecuadamente, puede distorsionar la señal, especialmente en espectros con picos superpuestos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dac104c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shirley_correction(raman_shift, intensity):\n",
    "    \"\"\"\n",
    "    Aplica la corrección de Shirley para un espectro.\n",
    "    \n",
    "    Parameters:\n",
    "        raman_shift (array-like): Valores del eje X (Raman Shift).\n",
    "        intensity (array-like): Intensidades del espectro (eje Y).\n",
    "        \n",
    "    Returns:\n",
    "        corrected_intensity (array-like): Intensidades corregidas.\n",
    "    \"\"\"\n",
    "    if len(raman_shift) != len(intensity):\n",
    "        raise ValueError(\"La longitud de 'Ramanshift' y la intensidad no coincide.\")\n",
    "    \n",
    "    corrected_intensity = intensity.copy()\n",
    "    start = corrected_intensity[0]\n",
    "    end = corrected_intensity[-1]\n",
    "    \n",
    "    for _ in range(100):  # Máximo 100 iteraciones\n",
    "        background = start + (end - start) * np.cumsum(corrected_intensity) / np.sum(corrected_intensity)\n",
    "        corrected_intensity = intensity - background\n",
    "        corrected_intensity[corrected_intensity < 0] = 0  # Evitar valores negativos\n",
    "    \n",
    "    return corrected_intensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91a797a",
   "metadata": {},
   "outputs": [],
   "source": [
    "raman_shift = df['Ramanshift'].values\n",
    "corrected_spectra = {}\n",
    "\n",
    "for col in df.columns[1:]:\n",
    "    intensity = df[col].values\n",
    "    # Validar longitud y ajustar si es necesario\n",
    "    if len(raman_shift) == len(intensity):\n",
    "        corrected_spectra[col] = shirley_correction(raman_shift, intensity)\n",
    "    elif len(raman_shift) > len(intensity):\n",
    "        # Alinear con raman_shift recortando\n",
    "        intensity = np.pad(intensity, (0, len(raman_shift) - len(intensity)), constant_values=0)\n",
    "        corrected_spectra[col] = shirley_correction(raman_shift, intensity)\n",
    "    else:\n",
    "        print(f\"Advertencia: La columna '{col}' tiene más datos que 'Ramanshift'. Será recortada.\")\n",
    "        intensity = intensity[:len(raman_shift)]\n",
    "        corrected_spectra[col] = shirley_correction(raman_shift, intensity)\n",
    "\n",
    "# Crear un DataFrame con los datos corregidos\n",
    "df_corrected = pd.DataFrame(corrected_spectra)\n",
    "df_corrected.insert(0, 'Ramanshift', raman_shift)\n",
    "\n",
    "# Graficar los espectros corregidos\n",
    "plt.figure(figsize=(14, 10))\n",
    "for col in df_corrected.columns[1:]:\n",
    "    plt.plot(df_corrected['Ramanshift'], df_corrected[col], alpha=0.6)\n",
    "\n",
    "plt.title(\"Espectros Raman Corregidos (Shirley)\", fontsize=16)\n",
    "plt.xlabel(\"Raman Shift (cm⁻¹)\", fontsize=14)\n",
    "plt.ylabel(\"Intensidad Corregida\", fontsize=14)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296ebc2d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
