{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "170103b0",
   "metadata": {},
   "source": [
    "### IMPORTACIONES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ebca0f4-6ccb-4b81-bfd4-b4c137b0f819",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re #regex para validar si existe subfijos\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "from scipy.signal import savgol_filter\n",
    "from sklearn.decomposition import PCA\n",
    "from numpy import trapz\n",
    "from scipy.ndimage import gaussian_filter1d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a320962-6177-4040-8293-a6d0225bd906",
   "metadata": {},
   "source": [
    "### LECTURA DE ARCHIVOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "696c7108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Ramanshift  collagen  collagen.1  collagen.2  collagen.3  collagen.4  \\\n",
      "0     1801.26     0.117       0.123       0.098       0.097       0.115   \n",
      "1     1797.41     0.118       0.124       0.099       0.098       0.116   \n",
      "2     1793.55     0.119       0.124       0.100       0.098       0.117   \n",
      "3     1789.69     0.118       0.122       0.099       0.097       0.117   \n",
      "4     1785.84     0.118       0.121       0.099       0.096       0.116   \n",
      "\n",
      "   collagen.5  collagen.6  collagen.7  collagen.8  ...  DNA.100  DNA.101  \\\n",
      "0       0.129       0.130       0.144       0.129  ...    0.154    0.150   \n",
      "1       0.130       0.131       0.145       0.129  ...    0.154    0.152   \n",
      "2       0.131       0.132       0.145       0.130  ...    0.155    0.153   \n",
      "3       0.131       0.132       0.146       0.131  ...    0.155    0.154   \n",
      "4       0.130       0.131       0.146       0.131  ...    0.155    0.155   \n",
      "\n",
      "   DNA.102  DNA.103  DNA.104  DNA.105  DNA.106  DNA.107  DNA.108  DNA.109  \n",
      "0    0.154    0.164    0.157    0.158    0.152    0.147    0.139    0.148  \n",
      "1    0.155    0.164    0.158    0.160    0.153    0.147    0.140    0.149  \n",
      "2    0.156    0.165    0.160    0.161    0.154    0.148    0.141    0.150  \n",
      "3    0.157    0.165    0.160    0.163    0.155    0.149    0.142    0.151  \n",
      "4    0.157    0.166    0.160    0.163    0.155    0.149    0.143    0.151  \n",
      "\n",
      "[5 rows x 732 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Lee el archivo CSV\n",
    "df = pd.read_csv('limpio.csv', delimiter=',')\n",
    "\n",
    "# Muestra las primeras filas del DataFrame para verificar\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d2e095",
   "metadata": {},
   "source": [
    " ### Verificamos si se tiene los subfijos al leer el archivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6da0c3c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se eliminaron los sufijos num√©ricos de los encabezados.\n",
      "   Ramanshift  collagen  collagen  collagen  collagen  collagen  collagen  \\\n",
      "0     1801.26     0.117     0.123     0.098     0.097     0.115     0.129   \n",
      "1     1797.41     0.118     0.124     0.099     0.098     0.116     0.130   \n",
      "2     1793.55     0.119     0.124     0.100     0.098     0.117     0.131   \n",
      "3     1789.69     0.118     0.122     0.099     0.097     0.117     0.131   \n",
      "4     1785.84     0.118     0.121     0.099     0.096     0.116     0.130   \n",
      "\n",
      "   collagen  collagen  collagen  ...    DNA    DNA    DNA    DNA    DNA  \\\n",
      "0     0.130     0.144     0.129  ...  0.154  0.150  0.154  0.164  0.157   \n",
      "1     0.131     0.145     0.129  ...  0.154  0.152  0.155  0.164  0.158   \n",
      "2     0.132     0.145     0.130  ...  0.155  0.153  0.156  0.165  0.160   \n",
      "3     0.132     0.146     0.131  ...  0.155  0.154  0.157  0.165  0.160   \n",
      "4     0.131     0.146     0.131  ...  0.155  0.155  0.157  0.166  0.160   \n",
      "\n",
      "     DNA    DNA    DNA    DNA    DNA  \n",
      "0  0.158  0.152  0.147  0.139  0.148  \n",
      "1  0.160  0.153  0.147  0.140  0.149  \n",
      "2  0.161  0.154  0.148  0.141  0.150  \n",
      "3  0.163  0.155  0.149  0.142  0.151  \n",
      "4  0.163  0.155  0.149  0.143  0.151  \n",
      "\n",
      "[5 rows x 732 columns]\n"
     ]
    }
   ],
   "source": [
    "if any(re.search(r'\\.\\d+$', col) for col in df.columns):\n",
    "    # Si hay columnas con sufijos, eliminarlos\n",
    "    df.columns = [re.sub(r'\\.\\d+$', '', col) for col in df.columns]\n",
    "    print(\"Se eliminaron los sufijos num√©ricos de los encabezados.\")\n",
    "# Muestra las primeras filas del DataFrame para verificar\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "918efba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Encabezados √∫nicos:\n",
      "Index(['Ramanshift', 'collagen', 'glycogen', 'lipids', 'DNA'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "unique_headers = df.columns.unique()\n",
    "print(\"\\nEncabezados √∫nicos:\")\n",
    "print(unique_headers)\n",
    "\n",
    "# Identificar los tipos √∫nicos de valores en los encabezados\n",
    "unique_types = set(col for col in df.columns if col != \"Ramanshift\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae506a94-5230-4242-86ff-bcb332d1cf1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colores para cada tipo\n",
    "colors = plt.cm.tab20.colors  # Una paleta de colores suficientemente grande\n",
    "color_map = {unique: colors[i % len(colors)] for i, unique in enumerate(unique_types)}\n",
    "\n",
    "# Graficar cada tipo una sola vez en la leyenda\n",
    "plt.figure(figsize=(14, 10))\n",
    "\n",
    "for unique_type in unique_types:\n",
    "    # Filtrar las columnas correspondientes al tipo actual\n",
    "    columns = [col for col in df.columns if col.startswith(unique_type)]\n",
    "    \n",
    "    # Graficar todas las columnas del tipo actual\n",
    "    for col in columns:\n",
    "        plt.plot(df['Ramanshift'], df[col], color=color_map[unique_type], alpha=0.6)\n",
    "    \n",
    "    # Agregar una entrada en la leyenda solo para el tipo (una vez)\n",
    "    plt.plot([], [], label=unique_type, color=color_map[unique_type])  # Dummy plot for legend\n",
    "\n",
    "# Etiquetas y leyendas\n",
    "plt.title(\"Espectros Raman\", fontsize=16)\n",
    "plt.xlabel(\"Raman Shift (cm‚Åª¬π)\", fontsize=14)\n",
    "plt.ylabel(\"Intensidad\", fontsize=14)\n",
    "plt.legend(title=\"Tipos\", fontsize=12, loc='upper right', frameon=False)\n",
    "plt.grid(True)\n",
    "\n",
    "# Mostrar la gr√°fica\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "154327d0",
   "metadata": {},
   "source": [
    "### En este caso pediremos al usuario ingresar algun tipo para graficar, para tener una idea de como se ve los espectros para cada uno de los tipos existentes en el archivo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "401b8b95",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>PD:</b> Aqui solo se mostraran hasta 10 como cantidad maxima de columnas para tipo, es para una referencia y no tener una carga de datos excesiva \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd222d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurar el tipo de espectro que se desea graficar\n",
    "#tipo_espectro = input(f\"Ingrese el tipo de espectro para graficar (opciones: {', '.join(unique_types)}): \").strip()\n",
    "tipo_espectro = \"collagen\"\n",
    "# Filtrar las columnas correspondientes al tipo de espectro ingresado\n",
    "columnas_tipo = [col for col in df.columns if col.startswith(tipo_espectro)]\n",
    "\n",
    "if columnas_tipo:\n",
    "    # Limitar el n√∫mero de columnas graficadas\n",
    "    max_columns = 10\n",
    "    columnas_tipo = columnas_tipo[:max_columns]\n",
    "\n",
    "    # Reducir la cantidad de datos graficados\n",
    "    sampled_df = df.iloc[::10, :]\n",
    "\n",
    "    # Crear la gr√°fica\n",
    "    plt.figure(figsize=(14, 8))\n",
    "\n",
    "    # Graficar todas las l√≠neas sin leyenda\n",
    "    for col in columnas_tipo:\n",
    "        plt.plot(sampled_df['Ramanshift'], sampled_df[col], alpha=0.7)\n",
    "\n",
    "    # A√±adir una entrada √∫nica en la leyenda para el tipo\n",
    "    plt.plot([], [], label=tipo_espectro, color='black') \n",
    "\n",
    "    # Etiquetas y leyenda\n",
    "    plt.title(f\"Espectro Raman - {tipo_espectro} (muestra de columnas y filas)\", fontsize=16)\n",
    "    plt.xlabel(\"Raman Shift (cm‚Åª¬π)\", fontsize=14)\n",
    "    plt.ylabel(\"Intensidad\", fontsize=14)\n",
    "    plt.legend(title=\"Espectros\", fontsize=10, loc='upper right', frameon=False)\n",
    "    plt.grid(True)\n",
    "\n",
    "    # Mostrar la gr√°fica\n",
    "    plt.show()\n",
    "else:\n",
    "    print(f\"No se encontraron columnas para el tipo de espectro '{tipo_espectro}'. Verifique el nombre e intente nuevamente.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2ed2c0",
   "metadata": {},
   "source": [
    "# <center>Analisis PCA</center>\n",
    "### ¬øPor qu√© utilizar PCA en espectros?\n",
    "En datos espectrosc√≥picos (como los Raman), los conjuntos de datos suelen tener alta dimensionalidad y las variables (picos) pueden estar correlacionadas. El PCA es √∫til porque:\n",
    "\n",
    "**Reduce la dimensionalidad:** Permite analizar un n√∫mero menor de variables representativas. <br>\n",
    "**Captura patrones esenciales:** Identifica las caracter√≠sticas espectrales clave. <br>\n",
    "**Mejora la visualizaci√≥n:** Ayuda a visualizar datos complejos en gr√°ficos 2D o 3D.  <br>\n",
    "**Preprocesamiento:** Facilita la clasificaci√≥n o el an√°lisis posterior (por ejemplo, identificaci√≥n de muestras)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00109167",
   "metadata": {},
   "source": [
    "<img src=pca-analysis.gif>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1573d467",
   "metadata": {},
   "source": [
    "### C√°lculo del PCA\n",
    "**Calcular la matriz de covarianza:** Representa c√≥mo var√≠an las variables juntas.<br>\n",
    "**Obtener los valores y vectores propios:** Los valores propios determinan la importancia (varianza explicada) de cada componente, y los vectores propios indican la direcci√≥n de los nuevos ejes. <br>\n",
    "**Proyecci√≥n de los datos:** Transformar los datos originales en los nuevos ejes definidos por los componentes principales."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feea4ac0",
   "metadata": {},
   "source": [
    "### Aplicaci√≥n pr√°ctica en espectros\n",
    "#### En espectros Raman:\n",
    "\n",
    "**Objetivo:** Identificar patrones comunes entre muestras (como grupos qu√≠micos) o distinguir diferencias entre ellas. <br>\n",
    "**Componentes principales:** Representan caracter√≠sticas espectrales clave que explican la mayor√≠a de las variaciones entre los espectros. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "360ef353",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Limitaciones PCA:</b> Es una t√©cnica lineal, lo que significa que no captura relaciones no lineales en los datos.\n",
    "Los componentes principales pueden ser dif√≠ciles de interpretar f√≠sicamente.\n",
    "Depende de la correcta estandarizaci√≥n y limpieza de los datos.\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81cfbac",
   "metadata": {},
   "source": [
    "# <center>Fundamento matem√°tico</center>\n",
    "\n",
    "### 1. Matriz de datos\n",
    "Dado un conjunto de datos con \n",
    "ùëö\n",
    "m muestras y \n",
    "ùëõ\n",
    "n variables, representamos los datos en una matriz de datos \n",
    "ùëã\n",
    "X de tama√±o \n",
    "ùëö\n",
    "√ó\n",
    "ùëõ\n",
    "m√ón:\n",
    "$$\n",
    "X = \n",
    "\\begin{bmatrix}\n",
    "x_{11} & x_{12} & \\dots & x_{1n} \\\\\n",
    "x_{21} & x_{22} & \\dots & x_{2n} \\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "x_{m1} & x_{m2} & \\dots & x_{mn}\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Donde cada fila es una muestra, y cada columna es una variable (por ejemplo, la intensidad de un espectro en una longitud de onda espec√≠fica).\n",
    "\n",
    "### 2. Estandarizaci√≥n\n",
    "El PCA requiere que las variables tengan media 0 y desviaci√≥n est√°ndar 1. Para ello, estandarizamos cada variable:\n",
    "\n",
    "$$\n",
    "z_{ij} = \\frac{x_{ij} - \\mu_j}{\\sigma_j}\n",
    "$$\n",
    "\n",
    "#### 1. F√≥rmula para estandarizaci√≥n de los datos\n",
    "\n",
    "$$\n",
    "z_{ij} = \\frac{x_{ij} - \\mu_j}{\\sigma_j}\n",
    "$$\n",
    "\n",
    "Donde:\n",
    "\n",
    "- \\( \\mu_j \\): Media de la variable \\( j \\).\n",
    "- \\( \\sigma_j \\): Desviaci√≥n est√°ndar de la variable \\( j \\).\n",
    "\n",
    "Esto nos da una nueva matriz \\( Z \\), estandarizada.\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a30f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Volver a realizar la estandarizaci√≥n con las columnas corregidas\n",
    "data_no_suffix = df.drop(columns=[\"Ramanshift\"])  # Eliminar la columna 'Ramanshift'\n",
    "\n",
    "# Estandarizar los datos nuevamente\n",
    "scaler = StandardScaler()\n",
    "data_standardized_no_suffix = scaler.fit_transform(data_no_suffix)\n",
    "\n",
    "\n",
    "# Convertir la matriz estandarizada en un DataFrame para inspecci√≥n\n",
    "data_standardized_no_suffix_df = pd.DataFrame(data_standardized_no_suffix, columns=data_no_suffix.columns)\n",
    "\n",
    "# Mostrar las primeras filas del DataFrame estandarizado sin sufijos\n",
    "data_standardized_no_suffix_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084ff7a6",
   "metadata": {},
   "source": [
    "### 3. Matriz de covarianza\n",
    "\n",
    "La matriz de covarianza mide c√≥mo var√≠an las variables entre s√≠:\n",
    "\n",
    "$$\n",
    "C = \\frac{1}{m - 1} Z^\\top Z\n",
    "$$\n",
    "\n",
    "Donde:\n",
    "\n",
    "- \\( C \\): Es la matriz de covarianza (\\( n \\times n \\)).\n",
    "- \\( Z^\\top \\): La transpuesta de la matriz estandarizada \\( Z \\).\n",
    "\n",
    "Cada elemento de \\( C \\), \\( c_{ij} \\), mide la covarianza entre las variables \\( i \\) y \\( j \\):\n",
    "\n",
    "$$\n",
    "c_{ij} = \\frac{1}{m-1} \\sum_{k=1}^m (z_{ki} - \\bar{z}_i)(z_{kj} - \\bar{z}_j)\n",
    "$$\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c86d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular la matriz de covarianza a partir de los datos estandarizados\n",
    "covariance_matrix = np.cov(data_standardized_no_suffix.T)\n",
    "\n",
    "# Convertir la matriz de covarianza a un DataFrame para visualizaci√≥n\n",
    "covariance_matrix_df = pd.DataFrame(\n",
    "    covariance_matrix,\n",
    "    index=data_no_suffix.columns,\n",
    "    columns=data_no_suffix.columns\n",
    ")\n",
    "\n",
    "# Mostrar las primeras filas de la matriz de covarianza\n",
    "covariance_matrix_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c32b8d69",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Matriz De Covarianza Raman</b> Se ha calculado la matriz de covarianza a partir de los datos estandarizados. Esta matriz representa c√≥mo var√≠an las variables (columnas del espectro) entre s√≠.\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dcb2cc2",
   "metadata": {},
   "source": [
    "### 4. Descomposici√≥n en valores propios\n",
    "\n",
    "El PCA se basa en encontrar los vectores propios (\\( v \\)) y los valores propios (\\( \\lambda \\)) de la matriz de covarianza:\n",
    "\n",
    "$$\n",
    "C v = \\lambda v\n",
    "$$\n",
    "\n",
    "Donde:\n",
    "\n",
    "- \\( v \\): Es el vector propio (direcci√≥n del nuevo eje).\n",
    "- \\( \\lambda \\): Es el valor propio (cu√°nta varianza explica ese eje).\n",
    "\n",
    "Los valores propios est√°n ordenados de mayor a menor y representan la cantidad de varianza explicada por cada componente principal.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92da524e-c628-432e-87c5-9c763a9c68d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descomposici√≥n en valores propios y vectores propios\n",
    "eigenvalues, eigenvectors = np.linalg.eig(covariance_matrix)\n",
    "\n",
    "# Convertir los valores propios en un DataFrame para inspecci√≥n\n",
    "eigenvalues_df = pd.DataFrame(eigenvalues, columns=[\"Valor Propio\"])\n",
    "\n",
    "# Convertir los vectores propios en un DataFrame para inspecci√≥n\n",
    "eigenvectors_df = pd.DataFrame(\n",
    "    eigenvectors,\n",
    "    index=data_no_suffix.columns,\n",
    "    columns=[f\"PC{i+1}\" for i in range(eigenvectors.shape[1])]\n",
    ")\n",
    "\n",
    "# Mostrar los valores propios y vectores propios\n",
    "eigenvalues_df.head()\n",
    "eigenvectors_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8ed705-1eeb-4d38-a308-e506b0b689a3",
   "metadata": {},
   "source": [
    "*La descomposici√≥n en valores propios y vectores propios de la matriz de covarianza se ha realizado correctamente:*<br>\n",
    "**Valores propios (eigenvalues):** Indican la cantidad de varianza explicada por cada componente principal.<br>\n",
    "**Vectores propios (eigenvectors):** Representan las direcciones (ejes) de los nuevos componentes principales en el espacio original."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5315f3c6-7d58-45b1-8984-39f24fb0781d",
   "metadata": {},
   "source": [
    "### 5 Transformaci√≥n de los datos\n",
    "\n",
    "Los datos originales se transforman proyect√°ndolos en los ejes definidos por los vectores propios:\n",
    "\n",
    "$$\n",
    "T = Z V\n",
    "$$\n",
    "\n",
    "Donde:\n",
    "\n",
    "- \\( T \\): Matriz transformada (nuevos datos en el espacio de los componentes principales).\n",
    "- \\( V \\): Matriz cuyas columnas son los vectores propios (direcciones principales).\n",
    "\n",
    "Cada fila de \\( T \\) es la representaci√≥n de una muestra en el espacio reducido.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c1b839-699d-4a83-a82b-3c9dbd78c768",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proyecci√≥n de los datos originales en los ejes definidos por los componentes principales\n",
    "transformed_data = np.dot(data_standardized_no_suffix, eigenvectors)\n",
    "\n",
    "# Convertir los datos transformados en un DataFrame para inspecci√≥n\n",
    "transformed_data_df = pd.DataFrame(\n",
    "    transformed_data,\n",
    "    columns=[f\"PC{i+1}\" for i in range(transformed_data.shape[1])]\n",
    ")\n",
    "\n",
    "# Mostrar los primeros datos transformados\n",
    "transformed_data_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b51e995-7fcb-4e37-8a1e-73cd4061d5b8",
   "metadata": {},
   "source": [
    "*Resultados:* <br>\n",
    "**Cada fila:** Representa una muestra en el espacio PCA. <br>\n",
    "**Cada columna (PC1, PC2, ...):** Representa un componente principal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdedce14-c4aa-4c79-add1-5e865c4dbe3e",
   "metadata": {},
   "source": [
    "### 6. Varianza explicada\n",
    "\n",
    "La proporci√≥n de varianza explicada por cada componente principal es:\n",
    "\n",
    "$$\n",
    "\\text{Varianza explicada} = \\frac{\\lambda_i}{\\sum \\lambda}\n",
    "$$\n",
    "\n",
    "Esto nos dice cu√°nto contribuye cada componente principal a la variabilidad total de los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8193ece6-8c55-407d-a307-2966a6974fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular la varianza explicada por cada componente principal\n",
    "explained_variance = eigenvalues / np.sum(eigenvalues)\n",
    "\n",
    "# Calcular la varianza acumulada\n",
    "cumulative_variance = np.cumsum(explained_variance)\n",
    "\n",
    "pc1 = transformed_data[:, 0]\n",
    "pc2 = transformed_data[:, 1]\n",
    "\n",
    "# Crear un gr√°fico de dispersi√≥n utilizando PC1 y PC2\n",
    "#plt.figure(figsize=(10, 6))\n",
    "#plt.scatter(pc1, pc2, alpha=0.7, edgecolor='k')\n",
    "#plt.xlabel(\"Componente Principal 1 (PC1)\", fontsize=14)\n",
    "#plt.ylabel(\"Componente Principal 2 (PC2)\", fontsize=14)\n",
    "#plt.title(\"Proyecci√≥n de Espectros en el Espacio PCA\", fontsize=16)\n",
    "#plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8df87d4-264a-44eb-8de8-e7cb5753a7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Leer el archivo CSV y excluir la primera columna (ejemplo: Ramanshift)\n",
    "data = df.iloc[:, 1:]\n",
    "\n",
    "# Obtener las categor√≠as desde los nombres de las columnas\n",
    "# Se asume que los nombres de las columnas contienen las categor√≠as como parte del texto\n",
    "categories = [col.split('_')[0] for col in data.columns]  # Divide por un delimitador como \"_\" (ajusta seg√∫n tu formato)\n",
    "unique_categories = list(set(categories))  # Categor√≠as √∫nicas\n",
    "\n",
    "# Asignar un color √∫nico a cada categor√≠a\n",
    "colors = plt.cm.tab10.colors  # Paleta de colores\n",
    "category_colors = {category: colors[i % len(colors)] for i, category in enumerate(unique_categories)}\n",
    "\n",
    "# Escalar los datos\n",
    "scaler = StandardScaler()\n",
    "data_scaled = scaler.fit_transform(data.T)  # Transposici√≥n para que las caracter√≠sticas sean columnas\n",
    "\n",
    "# Aplicar PCA\n",
    "pca = PCA(n_components=2)\n",
    "pca_result = pca.fit_transform(data_scaled)\n",
    "\n",
    "# Graficar el PCA con colores por tipo\n",
    "plt.figure(figsize=(10, 6))\n",
    "for category in unique_categories:\n",
    "    indices = [i for i, cat in enumerate(categories) if cat == category]\n",
    "    plt.scatter(\n",
    "        pca_result[indices, 0],\n",
    "        pca_result[indices, 1],\n",
    "        label=category,\n",
    "        color=category_colors[category],\n",
    "        alpha=0.7,\n",
    "        edgecolor='k'\n",
    "    )\n",
    "\n",
    "# Etiquetas y leyenda\n",
    "plt.xlabel('PC1', fontsize=14)\n",
    "plt.ylabel('PC2', fontsize=14)\n",
    "plt.title('Proyecci√≥n PCA', fontsize=16)\n",
    "plt.legend(loc='best', fontsize=10)\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be35e3a",
   "metadata": {},
   "source": [
    "## <center>¬øPor qu√© suavizar los datos antes del PCA?</center>\n",
    "\n",
    "### Reducci√≥n de ruido: \n",
    "\n",
    "En espectros, el ruido puede distorsionar las se√±ales reales y hacer que el PCA se enfoque en variaciones no representativas.\n",
    "Suavizar elimina fluctuaciones peque√±as e irrelevantes, dejando solo las tendencias principales.<br>\n",
    "\n",
    "### Mejor representaci√≥n de los patrones:\n",
    "\n",
    "Las caracter√≠sticas significativas (picos y valles) de un espectro se destacan mejor despu√©s del suavizado.\n",
    "El PCA trabajar√° sobre se√±ales m√°s limpias y representativas, en lugar de desviaciones causadas por el ruido.\n",
    "\n",
    "### Reducir complejidad: \n",
    "\n",
    "Suavizar puede disminuir la cantidad de detalles excesivos en los datos, facilitando la identificaci√≥n de las principales componentes. \n",
    "\n",
    "\n",
    "### Mejor interpretaci√≥n de los resultados:\n",
    "\n",
    "Los componentes principales extra√≠dos del PCA ser√°n m√°s f√°ciles de relacionar con caracter√≠sticas relevantes de los datos (como picos en un espectro).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b198fd5e",
   "metadata": {},
   "source": [
    "## <center> ¬øCu√°ndo no es necesario suavizar? </center> \n",
    "Si los datos ya son de alta calidad y el ruido es m√≠nimo, el suavizado puede no ser necesario.\n",
    "Un exceso de suavizado puede eliminar detalles importantes, lo que podr√≠a llevar a perder informaci√≥n relevante."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec18de1",
   "metadata": {},
   "source": [
    "# <center>M√©todos de suavizado comunes</center>\n",
    "\n",
    "## **1. Savitzky-Golay Filter**\n",
    "- Realiza un ajuste polin√≥mico local en una ventana m√≥vil.\n",
    "- Ideal para espectros, ya que preserva los picos y las caracter√≠sticas de la se√±al.\n",
    "\n",
    "**F√≥rmula:**\n",
    "$$\n",
    "y'(t) = \\sum_{k=-m}^{m} c_k \\cdot x(t+k)\n",
    "$$\n",
    "\n",
    "Donde:\n",
    "\n",
    "- $$y'(t)$$: Se√±al suavizada.\n",
    "- $$c_k$$: Coeficientes del polinomio.\n",
    "- $$x(t+k)$$: Valores originales en la ventana m√≥vil.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a691cae",
   "metadata": {},
   "source": [
    "<img src=filtro-sg.ppm>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b9bf4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Par√°metros para suavizar\n",
    "window_length = 11  # Longitud de la ventana (debe ser impar)\n",
    "polyorder = 3       # Orden del polinomio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b15a71",
   "metadata": {},
   "source": [
    "### 1. <font color=\"blue\">window_length:</font> Longitud de la ventana\n",
    "**Definici√≥n:** Es el n√∫mero de puntos consecutivos que se utilizan para ajustar un polinomio en el proceso de suavizado.\n",
    "#### Requisitos:\n",
    "Debe ser un n√∫mero entero impar (por ejemplo, 5, 7, 9, 11, etc.).\n",
    "Debe ser mayor que el orden del polinomio (polyorder).\n",
    "### Impacto:\n",
    "**Ventana peque√±a:** El suavizado ser√° m√°s localizado y detallado, pero puede no eliminar bien el ruido.<br>\n",
    "**Ventana grande:** El suavizado ser√° m√°s amplio y eliminar√° m√°s ruido, pero podr√≠a borrar picos o detalles importantes.\n",
    "\n",
    "### 2. <font color=\"blue\">polyorder:</font> Orden del polinomio\n",
    "**Definici√≥n:** Es el grado del polinomio que se ajusta a los puntos dentro de cada ventana.\n",
    "### Requisitos:\n",
    "Debe ser un n√∫mero entero no negativo.\n",
    "Debe ser menor que el tama√±o de la ventana (window_length).\n",
    "### Impacto:\n",
    "**Orden bajo (e.g., 2 o 3):** Se ajusta a tendencias generales y no captura oscilaciones r√°pidas.<br>\n",
    "**Orden alto (e.g., 4 o m√°s):** Captura m√°s detalles locales, pero puede amplificar el ruido si se usa con datos ruidosos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c4f9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar Savitzky-Golay al dataset\n",
    "data_smoothed = savgol_filter(df.iloc[:, 1:], window_length=window_length, polyorder=polyorder, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c68874",
   "metadata": {},
   "source": [
    "### C√≥mo funciona <font color=\"blue\">savgol_filter</font>\n",
    "El filtro realiza un ajuste polin√≥mico en ventanas m√≥viles de datos. Dentro de cada ventana, se ajusta un polinomio de un grado espec√≠fico a los datos y luego se usa ese polinomio para calcular el valor suavizado del punto central.\n",
    "\n",
    "**Ventana m√≥vil:**<br>\n",
    "Es un subconjunto de datos de longitud definida por el par√°metro window_length.<br>\n",
    "La ventana se mueve a trav√©s de la se√±al, centrada en cada punto que se va a suavizar.<br>\n",
    "**Ajuste polin√≥mico:**<br>\n",
    "Dentro de cada ventana, se ajusta un polinomio de grado polyorder.<br>\n",
    "El valor del punto central de la ventana se reemplaza por el valor del polinomio ajustado.<br>\n",
    "**Repetici√≥n:**<br>\n",
    "El proceso se repite para cada punto de la se√±al, excepto en los extremos, donde la ventana no puede ser completamente centrada. En esos casos, se utiliza un m√©todo de extrapolaci√≥n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb1829c-1943-4121-bd2f-c09d6c300b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un DataFrame con los datos suavizados\n",
    "df_smoothed = pd.DataFrame(data_smoothed, columns=df.columns[1:])\n",
    "df_smoothed.insert(0, 'Ramanshift', df['Ramanshift'])  # Insertar de vuelta la columna 'Ramanshift' que quitamos para\n",
    "#poder suavizar\n",
    "\n",
    "# Obtener los tipos √∫nicos desde los nombres de las columnas\n",
    "unique_types = set(col.split('_')[0] for col in df.columns[1:])  # Ajusta el separador si es necesario\n",
    "\n",
    "# Crear un mapa de colores\n",
    "colors = plt.cm.tab20.colors  # con 20 colores si podra colorear\n",
    "color_map = {unique: colors[i % len(colors)] for i, unique in enumerate(unique_types)}\n",
    "\n",
    "# Graficar los espectros suavizados\n",
    "plt.figure(figsize=(14, 10))\n",
    "\n",
    "for unique_type in unique_types:\n",
    "    # Filtrar las columnas correspondientes al tipo actual\n",
    "    columns = [col for col in df.columns if col.startswith(unique_type)]\n",
    "    \n",
    "    # Graficar todas las columnas del tipo actual\n",
    "    for col in columns:\n",
    "        plt.plot(df_smoothed['Ramanshift'], df_smoothed[col], color=color_map[unique_type], alpha=0.6)\n",
    "    \n",
    "    # Agregar una entrada en la leyenda solo para el tipo (una vez)\n",
    "    plt.plot([], [], label=unique_type, color=color_map[unique_type])  # Dummy plot for legend\n",
    "\n",
    "# Etiquetas y leyendas\n",
    "plt.title(\"Espectros Raman Suavizados SG\", fontsize=16)\n",
    "plt.xlabel(\"Raman Shift (cm‚Åª¬π)\", fontsize=14)\n",
    "plt.ylabel(\"Intensidad Suavizada\", fontsize=14)\n",
    "plt.legend(title=\"Tipos\", fontsize=12, loc='upper right', frameon=False)\n",
    "plt.grid(True)\n",
    "\n",
    "# Mostrar la gr√°fica\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b36fd074",
   "metadata": {},
   "source": [
    "## 2. Filtro Gaussiano\n",
    "El filtro gaussiano es una t√©cnica de suavizado que se utiliza para reducir el ruido en los espectros (como los espectros Raman) preservando las caracter√≠sticas principales, como los picos. Este filtro aplica una convoluci√≥n entre los datos espectrales y una funci√≥n gaussiana, lo que aten√∫a las variaciones r√°pidas (ruido) y retiene los patrones de baja frecuencia (picos y formas importantes).\n",
    "\n",
    "### C√≥mo funciona el filtro gaussiano\n",
    "**Definici√≥n de la funci√≥n gaussiana:** La funci√≥n gaussiana es una curva en forma de campana que da m√°s peso a los puntos cercanos al valor central. Matem√°ticamente, se define como:\n",
    "\n",
    "$$\n",
    "G(x) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} e^{-\\frac{x^2}{2\\sigma^2}}\n",
    "$$\n",
    "\n",
    "Donde: <br>\n",
    "G(x): Valor de la funci√≥n gaussiana en un punto <br>\n",
    "œÉ: Desviaci√≥n est√°ndar, que determina el ancho de la curva gaussiana.\n",
    "\n",
    "**Aplicaci√≥n en el espectro:**\n",
    "\n",
    "* Se toma una ventana alrededor de cada punto del espectro.\n",
    "* Se calcula un promedio ponderado de los valores dentro de la ventana, donde los pesos est√°n determinados por la funci√≥n gaussiana. <br>\n",
    "\n",
    "**Atenuaci√≥n del ruido:**\n",
    "\n",
    "El ruido, que tiende a tener variaciones r√°pidas, se aten√∫a debido al promedio ponderado.\n",
    "Las caracter√≠sticas principales, como los picos del espectro, se preservan.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c617327",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Par√°metros para el filtro gaussiano\n",
    "sigma = 2  # Desviaci√≥n est√°ndar del filtro\n",
    "\n",
    "# Aplicar el filtro gaussiano a los datos espectrales\n",
    "data_smoothed_gaussian = gaussian_filter1d(df.iloc[:, 1:].values, sigma=sigma, axis=0)\n",
    "\n",
    "# Crear un DataFrame con los datos suavizados\n",
    "df_smoothed_gaussian = pd.DataFrame(data_smoothed_gaussian, columns=df.columns[1:])\n",
    "df_smoothed_gaussian.insert(0, 'Ramanshift', df['Ramanshift'])  # Insertar la columna 'Ramanshift'\n",
    "\n",
    "# Obtener los tipos √∫nicos desde los nombres de las columnas\n",
    "unique_types = set(col.split('_')[0] for col in df.columns[1:])  # Ajusta el separador si es necesario\n",
    "\n",
    "# Crear un mapa de colores\n",
    "colors = plt.cm.tab20.colors  # Paleta de colores suficientemente grande\n",
    "color_map = {unique: colors[i % len(colors)] for i, unique in enumerate(unique_types)}\n",
    "\n",
    "# Graficar los espectros suavizados\n",
    "plt.figure(figsize=(14, 10))\n",
    "\n",
    "for unique_type in unique_types:\n",
    "    # Filtrar las columnas correspondientes al tipo actual\n",
    "    columns = [col for col in df.columns if col.startswith(unique_type)]\n",
    "    \n",
    "    # Graficar todas las columnas del tipo actual\n",
    "    for col in columns:\n",
    "        plt.plot(df_smoothed_gaussian['Ramanshift'], df_smoothed_gaussian[col], color=color_map[unique_type], alpha=0.6)\n",
    "    \n",
    "    # Agregar una entrada en la leyenda solo para el tipo (una vez)\n",
    "    plt.plot([], [], label=unique_type, color=color_map[unique_type])  # Dummy plot for legend\n",
    "\n",
    "# Etiquetas y leyendas\n",
    "plt.title(\"Espectros Raman Suavizados con Filtro Gaussiano\", fontsize=16)\n",
    "plt.xlabel(\"Raman Shift (cm‚Åª¬π)\", fontsize=14)\n",
    "plt.ylabel(\"Intensidad Suavizada\", fontsize=14)\n",
    "plt.legend(title=\"Tipos\", fontsize=12, loc='upper right', frameon=False)\n",
    "plt.grid(True)\n",
    "\n",
    "# Mostrar la gr√°fica\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4bd452",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficar los espectros suavizados para comparar con colores diferentes por tipo\n",
    "plt.figure(figsize=(20, 8))\n",
    "\n",
    "# Crear un mapa de colores\n",
    "unique_types = set(col.split('_')[0] for col in df_smoothed_gaussian.columns[1:])\n",
    "colors = plt.cm.tab20.colors\n",
    "color_map = {unique: colors[i % len(colors)] for i, unique in enumerate(unique_types)}\n",
    "\n",
    "# Subplot para el filtro gaussiano\n",
    "plt.subplot(1, 2, 1)\n",
    "for unique_type in unique_types:\n",
    "    columns = [col for col in df_smoothed_gaussian.columns if col.startswith(unique_type)]\n",
    "    for col in columns:\n",
    "        plt.plot(df_smoothed_gaussian['Ramanshift'], df_smoothed_gaussian[col], color=color_map[unique_type], alpha=0.6)\n",
    "    plt.plot([], [], label=unique_type, color=color_map[unique_type])  # Dummy plot for legend\n",
    "plt.title(\"Filtro Gaussiano\", fontsize=16)\n",
    "plt.xlabel(\"Raman Shift (cm‚Åª¬π)\", fontsize=14)\n",
    "plt.ylabel(\"Intensidad Suavizada\", fontsize=14)\n",
    "plt.legend(title=\"Tipos\", fontsize=12, loc='upper right', frameon=False)\n",
    "plt.grid(True)\n",
    "\n",
    "# Subplot para el filtro Savitzky-Golay\n",
    "plt.subplot(1, 2, 2)\n",
    "for unique_type in unique_types:\n",
    "    columns = [col for col in df_smoothed.columns if col.startswith(unique_type)]\n",
    "    for col in columns:\n",
    "        plt.plot(df_smoothed['Ramanshift'], df_smoothed[col], color=color_map[unique_type], alpha=0.6)\n",
    "    plt.plot([], [], label=unique_type, color=color_map[unique_type])  # Dummy plot for legend\n",
    "plt.title(\"Filtro Savitzky-Golay\", fontsize=16)\n",
    "plt.xlabel(\"Raman Shift (cm‚Åª¬π)\", fontsize=14)\n",
    "plt.ylabel(\"Intensidad Suavizada\", fontsize=14)\n",
    "plt.legend(title=\"Tipos\", fontsize=12, loc='upper right', frameon=False)\n",
    "plt.grid(True)\n",
    "\n",
    "# Ajustar y mostrar\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff46c6e",
   "metadata": {},
   "source": [
    "**Filtro de Savitzky-Golay:**\n",
    "* Utiliza un ajuste polin√≥mico en una ventana m√≥vil.\n",
    "* Si los par√°metros de longitud de ventana (window_length) y orden del polinomio (polyorder) est√°n ajustados de manera conservadora, el resultado ser√° muy similar al de un filtro gaussiano. <br>\n",
    "\n",
    "**Filtro Gaussiano:**<br>\n",
    "* Realiza una convoluci√≥n con una funci√≥n gaussiana.\n",
    "* El par√°metro clave es ùúé (desviaci√≥n est√°ndar), que controla la suavidad.<bR>\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "Si la longitud de ventana de Savitzky-Golay y ùúé en el filtro gaussiano son equivalentes en t√©rminos de suavizado, las gr√°ficas resultantes ser√°n casi id√©nticas.\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d30a8da1",
   "metadata": {},
   "source": [
    "#### Diferencias:\n",
    "Calcula la diferencia absoluta entre los datos suavizados por cada filtro:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8c94b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "difference = df_smoothed_gaussian.iloc[:, 1:] - df_smoothed.iloc[:, 1:]\n",
    "print(difference.abs().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e87ecc",
   "metadata": {},
   "source": [
    "# <center>Normalizacion de los espectros</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c22f6c",
   "metadata": {},
   "source": [
    "Normalizar el espectro es un proceso que consiste en escalar o transformar los datos de un espectro a un rango o referencia com√∫n. Esto se hace para poder comparar diferentes espectros entre s√≠, y para eliminar variaciones aleatorias en la amplitud de cada intensidad.\n",
    "### M√©todos de Normalizaci√≥n y Sus Casos de Uso\n",
    "\n",
    "| **M√©todo**                 | **Prop√≥sito**                                                                 |\n",
    "|----------------------------|------------------------------------------------------------------------------|\n",
    "| **Escalado Min-Max**       | Cuando los datos necesitan estar en un rango espec√≠fico (por ejemplo, [0, 1]).|\n",
    "| **Z-Score (Estandarizaci√≥n)** | Cuando se necesita centrar y escalar los datos (por ejemplo, para PCA o agrupamiento). |\n",
    "| **Normalizaci√≥n por √Årea** | Comparar formas o perfiles (por ejemplo, en espectroscop√≠a o cromatograf√≠a).  |\n",
    "| **Normalizaci√≥n por M√°ximo** | Resaltar intensidades relativas (por ejemplo, en datos espectrales).          |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fafe6480",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Normalizaci√≥n por valor m√°ximo\n",
    "df_normalized_max = df.iloc[:, 1:].div(df.iloc[:, 1:].max(axis=0), axis=1)\n",
    "df_normalized_max.insert(0, 'Ramanshift', df['Ramanshift'])  # Reinsertar la columna 'Ramanshift'\n",
    "\n",
    "# 2. Normalizaci√≥n por √°rea bajo la curva\n",
    "areas = trapz(df.iloc[:, 1:].values, x=df['Ramanshift'].values, axis=0)\n",
    "df_normalized_area = df.iloc[:, 1:].div(areas, axis=1)\n",
    "df_normalized_area.insert(0, 'Ramanshift', df['Ramanshift'])\n",
    "\n",
    "# 3. Normalizaci√≥n Z-Score\n",
    "scaler = StandardScaler()\n",
    "data_scaled = scaler.fit_transform(df.iloc[:, 1:])\n",
    "df_normalized_zscore = pd.DataFrame(data_scaled, columns=df.columns[1:])\n",
    "df_normalized_zscore.insert(0, 'Ramanshift', df['Ramanshift'])\n",
    "\n",
    "# Mostrar las primeras filas de los DataFrames normalizados para inspecci√≥n\n",
    "\n",
    "df_normalized_max.head()\n",
    "df_normalized_area.head()\n",
    "df_normalized_zscore.head()\n",
    "#print(df_normalized_zscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005ce650",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_normalized_max.to_csv('normalized_max.csv', index=False)\n",
    "df_normalized_area.to_csv('normalized_area.csv', index=False)\n",
    "df_normalized_zscore.to_csv('normalized_zscore.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf67fd27-6462-45a9-9a21-3205367b8ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1. Eliminar sufijos num√©ricos de los nombres de las columnas\n",
    "df.columns = [re.sub(r'\\.\\d+$', '', col) for col in df.columns]\n",
    "\n",
    "# 2. Normalizaci√≥n por diferentes m√©todos\n",
    "\n",
    "# Normalizaci√≥n por valor m√°ximo\n",
    "df_normalized_max = df.iloc[:, 1:].div(df.iloc[:, 1:].max(axis=0), axis=1)\n",
    "df_normalized_max.insert(0, 'Ramanshift', df['Ramanshift'])\n",
    "\n",
    "# Normalizaci√≥n por √°rea bajo la curva\n",
    "areas = trapz(df.iloc[:, 1:].values, x=df['Ramanshift'].values, axis=0)\n",
    "df_normalized_area = df.iloc[:, 1:].div(areas, axis=1)\n",
    "df_normalized_area.insert(0, 'Ramanshift', df['Ramanshift'])\n",
    "\n",
    "# Normalizaci√≥n Z-Score\n",
    "scaler = StandardScaler()\n",
    "data_scaled = scaler.fit_transform(df.iloc[:, 1:])\n",
    "df_normalized_zscore = pd.DataFrame(data_scaled, columns=df.columns[1:])\n",
    "df_normalized_zscore.insert(0, 'Ramanshift', df['Ramanshift'])\n",
    "\n",
    "# Funci√≥n para graficar espectros\n",
    "def plot_normalized_spectra(df_normalized, title):\n",
    "    # Obtener tipos √∫nicos\n",
    "    unique_types = set(col.split('_')[0] for col in df_normalized.columns[1:])\n",
    "    \n",
    "    # Crear un mapa de colores\n",
    "    colors = plt.cm.tab20.colors\n",
    "    color_map = {unique: colors[i % len(colors)] for i, unique in enumerate(unique_types)}\n",
    "    \n",
    "    # Graficar\n",
    "    plt.figure(figsize=(14, 10))\n",
    "    for unique_type in unique_types:\n",
    "        columns = [col for col in df_normalized.columns if col.startswith(unique_type)]\n",
    "        for col in columns:\n",
    "            plt.plot(df_normalized['Ramanshift'], df_normalized[col], color=color_map[unique_type], alpha=0.6)\n",
    "        plt.plot([], [], label=unique_type, color=color_map[unique_type])  # Dummy plot for legend\n",
    "    \n",
    "    # Etiquetas y leyendas\n",
    "    plt.title(title, fontsize=16)\n",
    "    plt.xlabel(\"Raman Shift (cm‚Åª¬π)\", fontsize=14)\n",
    "    plt.ylabel(\"Intensidad Normalizada\", fontsize=14)\n",
    "    plt.legend(title=\"Tipos\", fontsize=12, loc='upper right', frameon=False)\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d7ccda-8baa-4ed8-9416-b488829d2db0",
   "metadata": {},
   "source": [
    "## <center>Graficos normalizados, por tipo de normalizacion</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc311697-362f-478a-b435-70fb0b793c0b",
   "metadata": {},
   "source": [
    "### Normalizaci√≥n por M√°ximo\n",
    "\n",
    "La **normalizaci√≥n por m√°ximo** ajusta los datos dividiendo cada valor por el valor m√°ximo en su columna. Esto escala los valores al rango \\([0, 1]\\).\n",
    "\n",
    "**F√≥rmula:**\n",
    "\n",
    "$$\n",
    "x_{\\text{norm}} = \\frac{x}{x_{\\text{max}}}\n",
    "$$\n",
    "\n",
    "Donde:\n",
    "- \\( x \\): Valor original.\n",
    "- \\( x_{\\text{max}} \\): Valor m√°ximo de la columna correspondiente.\n",
    "\n",
    "#### Prop√≥sito:\n",
    "- Resaltar las intensidades relativas en los datos.\n",
    "- Comparar espectros escalados a un rango uniforme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c373ede-22e1-4833-a526-7d5323297bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_normalized_spectra(df_normalized_max, \"Espectros Normalizados por M√°ximo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40571e65-3060-4cff-b1ba-8cdd1a7eacea",
   "metadata": {},
   "source": [
    "### Normalizados por √Årea\n",
    "La normalizaci√≥n por √°rea es un m√©todo com√∫n para escalar datos espectrales, como los espectros Raman, que ajusta cada valor del espectro dividiendo por el √°rea total bajo la curva. Esto asegura que el √°rea total de cada espectro sea igual a 1, permitiendo comparaciones m√°s equitativas de las formas relativas de los espectros.\n",
    "\n",
    "#### C√≥mo funciona la Normalizaci√≥n por √Årea\n",
    "\n",
    "#### Calcular el √°rea bajo la curva (AUC):\n",
    "El √°rea se calcula como la integral de la intensidad a lo largo de los valores del desplazamiento Raman (o eje X). \n",
    "\n",
    "En datos discretos, como los espectros Raman, se utiliza una suma aproximada o la **regla del trapecio** para estimar esta integral:\n",
    "\n",
    "$$\n",
    "A = \\int f(x) \\, dx \\approx \\sum_{i=1}^{n-1} \\frac{f(x_{i+1}) + f(x_i)}{2} (x_{i+1} - x_i)\n",
    "$$\n",
    "\n",
    "En Python, esto se logra con la funci√≥n `numpy.trapz`.\n",
    "\n",
    "---\n",
    "\n",
    "#### Dividir cada valor por el √°rea total:\n",
    "Una vez calculada el √°rea (\\( A \\)), cada valor del espectro (\\( x \\)) se divide por \\( A \\):\n",
    "\n",
    "$$\n",
    "x_{\\text{norm}} = \\frac{x}{A}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "#### Resultado:\n",
    "- Los valores del espectro escalados estar√°n en una **escala relativa**.\n",
    "- El √°rea bajo la curva del espectro normalizado ser√° igual a **1**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3f0649-632f-429b-aab4-125af7052b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_normalized_spectra(df_normalized_area, \"Espectros Normalizados por √Årea\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a94ab50-ff95-468d-a6e8-73593ed2a539",
   "metadata": {},
   "source": [
    "## Normalizacion Z-Score (Estandarizaci√≥n)\n",
    "La normalizaci√≥n Z-Score, tambi√©n conocida como estandarizaci√≥n, transforma los datos para que cada variable tenga una media de 0 y una desviaci√≥n est√°ndar de 1. Este m√©todo es especialmente √∫til para an√°lisis estad√≠sticos como el PCA, donde las escalas de las variables pueden afectar el resultado.\n",
    "\n",
    "### F√≥rmula del Z-Score\n",
    "\n",
    "Cada valor se transforma usando la f√≥rmula:\n",
    "\n",
    "$$\n",
    "z = \\frac{x - \\mu}{\\sigma}\n",
    "$$\n",
    "\n",
    "Donde:\n",
    "- \\( x \\): Valor original.\n",
    "- \\( \\mu \\): Media de la variable.\n",
    "- \\( \\sigma \\): Desviaci√≥n est√°ndar de la variable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b247bc7-2e33-4c4e-b4b1-bb19a02f8a6c",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Interpretaci√≥n de \n",
    "ùúé\n",
    "œÉ en espectros Raman</b> \n",
    "    <br><font color=red>Desviaci√≥n est√°ndar peque√±a:</font> La intensidad de los valores est√° m√°s concentrada alrededor de la media, indicando picos m√°s homog√©neos.<br>\n",
    "    <font color=red>Desviaci√≥n est√°ndar grande:</font> Los valores de intensidad est√°n m√°s dispersos, indicando variaciones significativas en el espectro.<br>\n",
    "</div>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1120912-7c57-42b6-9cdc-3c31b81036e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_normalized_spectra(df_normalized_zscore, \"Espectros Normalizados por Z-Score\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8b628a",
   "metadata": {},
   "source": [
    "# Correcci√≥n de Shirley\n",
    "## ¬øPor qu√© se necesita la correcci√≥n de Shirley?\n",
    "\n",
    "### **Presencia de un fondo no lineal:**\n",
    "- Los espectros suelen incluir un fondo causado por:\n",
    "  - Efectos secundarios.\n",
    "  - Ruido.\n",
    "  - Respuesta del instrumento.\n",
    "- Este fondo no lineal puede superponerse con los picos de inter√©s, complicando su an√°lisis.\n",
    "\n",
    "### **An√°lisis preciso de los picos:**\n",
    "- Los picos en un espectro representan caracter√≠sticas f√≠sicas o qu√≠micas clave, como:\n",
    "  - Vibraciones moleculares.\n",
    "  - Estados electr√≥nicos.\n",
    "- La correcci√≥n de Shirley elimina el fondo para que los picos sean m√°s visibles y se puedan analizar con mayor precisi√≥n.\n",
    "\n",
    "### **Estandarizaci√≥n:**\n",
    "- Al eliminar el fondo, los espectros de diferentes muestras o instrumentos se pueden comparar directamente.\n",
    "\n",
    "---\n",
    "\n",
    "## ¬øC√≥mo funciona la correcci√≥n de Shirley?\n",
    "- La correcci√≥n de Shirley modela el fondo como una curva no lineal y lo ajusta iterativamente:\n",
    "  1. El √°rea **debajo de la curva ajustada** se iguala al √°rea **sobre la curva** (en un rango definido del espectro).\n",
    "  2. Se asume que la contribuci√≥n del fondo **aumenta con la intensidad acumulativa** del espectro.\n",
    "\n",
    "---\n",
    "\n",
    "## Aplicaciones de la correcci√≥n de Shirley\n",
    "\n",
    "### **XPS (Espectroscop√≠a de Fotoelectrones de Rayos X):**\n",
    "- Elimina el fondo causado por emisiones secundarias de electrones.\n",
    "- Permite determinar con precisi√≥n la composici√≥n elemental y los estados qu√≠micos.\n",
    "\n",
    "### **Espectroscop√≠a Raman:**\n",
    "- Corrige fondos de fluorescencia u otras se√±ales amplias que ocultan los picos Raman.\n",
    "\n",
    "### **Espectroscop√≠a UV-Vis e Infrarroja:**\n",
    "- Corrige l√≠neas de base causadas por efectos de dispersi√≥n o absorci√≥n.\n",
    "\n",
    "---\n",
    "\n",
    "## Ventajas de la correcci√≥n de Shirley\n",
    "\n",
    "### **Preservaci√≥n de los picos:**\n",
    "- Conserva la forma y el √°rea de los picos, lo que la hace ideal para an√°lisis cuantitativos y cualitativos.\n",
    "\n",
    "### **Versatilidad:**\n",
    "- Es efectiva para fondos no lineales, lo que la hace aplicable a una amplia variedad de t√©cnicas espectrosc√≥picas.\n",
    "\n",
    "### **Ajuste iterativo:**\n",
    "- Proporciona un m√©todo flexible que converge hacia una l√≠nea de base precisa.\n",
    "\n",
    "---\n",
    "\n",
    "## Limitaciones de la correcci√≥n de Shirley\n",
    "\n",
    "### **Requiere tiempo:**\n",
    "- Los procesos iterativos pueden ser computacionalmente costosos para conjuntos de datos grandes.\n",
    "\n",
    "### **Dependencia de los puntos iniciales/finales:**\n",
    "- Es necesario definir correctamente el rango del espectro donde se aplicar√° la correcci√≥n.\n",
    "\n",
    "### **Riesgo de sobrecorrecci√≥n:**\n",
    "- Si no se aplica adecuadamente, puede distorsionar la se√±al, especialmente en espectros con picos superpuestos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dac104c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shirley_correction(raman_shift, intensity):\n",
    "    \"\"\"\n",
    "    Aplica la correcci√≥n de Shirley para un espectro.\n",
    "    \n",
    "    Parameters:\n",
    "        raman_shift (array-like): Valores del eje X (Raman Shift).\n",
    "        intensity (array-like): Intensidades del espectro (eje Y).\n",
    "        \n",
    "    Returns:\n",
    "        corrected_intensity (array-like): Intensidades corregidas.\n",
    "    \"\"\"\n",
    "    if len(raman_shift) != len(intensity):\n",
    "        raise ValueError(\"La longitud de 'Ramanshift' y la intensidad no coincide.\")\n",
    "    \n",
    "    corrected_intensity = intensity.copy()\n",
    "    start = corrected_intensity[0]\n",
    "    end = corrected_intensity[-1]\n",
    "    \n",
    "    for _ in range(100):  # M√°ximo 100 iteraciones\n",
    "        background = start + (end - start) * np.cumsum(corrected_intensity) / np.sum(corrected_intensity)\n",
    "        corrected_intensity = intensity - background\n",
    "        corrected_intensity[corrected_intensity < 0] = 0  # Evitar valores negativos\n",
    "    \n",
    "    return corrected_intensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91a797a",
   "metadata": {},
   "outputs": [],
   "source": [
    "raman_shift = df['Ramanshift'].values\n",
    "corrected_spectra = {}\n",
    "\n",
    "for col in df.columns[1:]:\n",
    "    intensity = df[col].values\n",
    "    # Validar longitud y ajustar si es necesario\n",
    "    if len(raman_shift) == len(intensity):\n",
    "        corrected_spectra[col] = shirley_correction(raman_shift, intensity)\n",
    "    elif len(raman_shift) > len(intensity):\n",
    "        # Alinear con raman_shift recortando\n",
    "        intensity = np.pad(intensity, (0, len(raman_shift) - len(intensity)), constant_values=0)\n",
    "        corrected_spectra[col] = shirley_correction(raman_shift, intensity)\n",
    "    else:\n",
    "        print(f\"Advertencia: La columna '{col}' tiene m√°s datos que 'Ramanshift'. Ser√° recortada.\")\n",
    "        intensity = intensity[:len(raman_shift)]\n",
    "        corrected_spectra[col] = shirley_correction(raman_shift, intensity)\n",
    "\n",
    "# Crear un DataFrame con los datos corregidos\n",
    "df_corrected = pd.DataFrame(corrected_spectra)\n",
    "df_corrected.insert(0, 'Ramanshift', raman_shift)\n",
    "\n",
    "# Graficar los espectros corregidos\n",
    "plt.figure(figsize=(14, 10))\n",
    "for col in df_corrected.columns[1:]:\n",
    "    plt.plot(df_corrected['Ramanshift'], df_corrected[col], alpha=0.6)\n",
    "\n",
    "plt.title(\"Espectros Raman Corregidos (Shirley)\", fontsize=16)\n",
    "plt.xlabel(\"Raman Shift (cm‚Åª¬π)\", fontsize=14)\n",
    "plt.ylabel(\"Intensidad Corregida\", fontsize=14)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296ebc2d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
